{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurog Internship: (Task 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Vizualization & Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For Datetime Handling\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "\n",
    "# Technical Analysis Library Modules\n",
    "from ta.momentum import AwesomeOscillatorIndicator\n",
    "from ta.volume import OnBalanceVolumeIndicator\n",
    "from ta.momentum import StochRSIIndicator\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import PSARIndicator\n",
    "from ta.trend import ADXIndicator\n",
    "from ta.trend import SMAIndicator\n",
    "from ta.trend import EMAIndicator\n",
    "\n",
    "# Other Necessary Libraries\n",
    "import quantstats as qs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tailer\n",
    "import copy\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative path to the CSV file\n",
    "csv_filename_1 = \"BTCUSDT_1_Minute_From_2020_Till_Now.csv\"\n",
    "csv_filename_2 = \"all_models_info.csv\"\n",
    "# csv_filename_3 = \"\n",
    "\n",
    "# Settig Up The Directory From The Directory Hierarchy\n",
    "# Get the notebook's current directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Go up one level to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, os.pardir))\n",
    "\n",
    "# Go to the main data directory\n",
    "data_dir = os.path.join(parent_dir, \"data\")\n",
    "\n",
    "# Create the full path to the output CSV file 1 in the 'ohlc' directory within 'data'\n",
    "ohlc_dir = os.path.join(data_dir, \"ohlc\")\n",
    "full_csv_path_1 = os.path.join(ohlc_dir, csv_filename_1)\n",
    "\n",
    "# Create the full path to the output CSV file 2 in the 'info' directory within 'models' directory within 'data'\n",
    "models_dir = os.path.join(data_dir, \"models\")\n",
    "models_info_dir = os.path.join(models_dir, \"info\")\n",
    "full_csv_path_2 = os.path.join(models_info_dir, csv_filename_2)\n",
    "\n",
    "# # Create the full path to the output CSV file 3 in the 'ledger' directory within 'models' directory within 'data'\n",
    "# models_ledger_dir = os.path.join(models_dir, \"ledger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# All Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the timeframe of the dataframe's index\n",
    "def get_timeframe(df):\n",
    "    \"\"\"\n",
    "    Returns the inferred timeframe (frequency) of the datetime index of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with datetime index.\n",
    "    \n",
    "    Returns:\n",
    "        str: Timeframe (frequency) of the datetime index, e.g., '4H', '1D'.\n",
    "    \"\"\"\n",
    "    # Check if the index is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "        raise ValueError(\"DataFrame index must be datetime.\")\n",
    "    \n",
    "    # Infer the frequency of the datetime index\n",
    "    frequency = pd.infer_freq(df.index)\n",
    "\n",
    "    if len(frequency) == 1:\n",
    "        frequency = '1' + frequency\n",
    "    \n",
    "    if frequency is None:\n",
    "        raise ValueError(\"Unable to infer the frequency of the datetime index.\")\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "# Function that extracts previous 'N' times data from the latest data\n",
    "def get_past_data(df, period, timeframe):\n",
    "    \"\"\"\n",
    "    Returns data from the past specified period and aligns the start and end dates with the given timeframe.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with datetime index.\n",
    "        period (str): Period string, e.g., '1Y' for one year, '1M' for one month.\n",
    "        timeframe (str): Timeframe string, e.g., '1M' for one month, '4H' for four hours, '15T' for fifteen minutes.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame filtered by the specified period and aligned with the timeframe.\n",
    "    \"\"\"\n",
    "    # Check if the index is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "        raise ValueError(\"DataFrame index must be datetime.\")\n",
    "    \n",
    "    # Mapping period strings to DateOffset arguments\n",
    "    period_mapping = {\n",
    "        'Y': 'years',\n",
    "        'M': 'months',\n",
    "        'W': 'weeks',\n",
    "        'D': 'days',\n",
    "        'H': 'hours',\n",
    "        'T': 'minutes'\n",
    "    }\n",
    "    \n",
    "    # Extract the time unit and quantity for the period\n",
    "    period_unit = period[-1]\n",
    "    period_quantity = int(period[:-1])\n",
    "    \n",
    "    # Get the corresponding DateOffset argument for the period\n",
    "    if period_unit not in period_mapping:\n",
    "        raise ValueError(\"Invalid period format. Use formats like '1Y', '1M', '1W', '1D', etc.\")\n",
    "    \n",
    "    period_offset_arg = period_mapping[period_unit]\n",
    "    period_offset = pd.DateOffset(**{period_offset_arg: period_quantity})\n",
    "    \n",
    "    # Get the last date in the DataFrame\n",
    "    last_date = df.index[-1]\n",
    "    \n",
    "    # Calculate the start date\n",
    "    start_date = last_date - period_offset\n",
    "    \n",
    "    # Align start_date to the nearest preceding datetime divisible by the timeframe\n",
    "    freq = pd.tseries.frequencies.to_offset(timeframe)\n",
    "    aligned_start_date = start_date.floor(freq)\n",
    "    \n",
    "    # Align end_date to the nearest preceding datetime divisible by the timeframe\n",
    "    aligned_end_date = last_date.floor(freq)\n",
    "    \n",
    "    # Filter the DataFrame for the desired date range\n",
    "    filtered_df_last = df[(df.index >= aligned_start_date) & (df.index <= aligned_end_date)]\n",
    "    filtered_df_first = df[(df.index < aligned_start_date)]\n",
    "    \n",
    "    return filtered_df_first, filtered_df_last\n",
    "\n",
    "# Function that extracts the last n/2 rows of the csv\n",
    "def get_csv_tail(filepath, max_rows=1):\n",
    "    with open(filepath) as file:\n",
    "        # Read the header\n",
    "        header = file.readline().strip()\n",
    "        \n",
    "        # Read the last lines of the file\n",
    "        last_lines = tailer.tail(file, max_rows)\n",
    "        last_lines = last_lines[1:]\n",
    "        \n",
    "    # Combine the header with the last lines\n",
    "    combined_lines = '\\n'.join([header] + last_lines)\n",
    "\n",
    "    return io.StringIO(combined_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Function To Convert DF To Any Timeframe) - Taken From The Previous Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions converts the dataframe into any given time frame.\n",
    "def convert_1m_to_any_timeframe(df: pd.DataFrame, timeframe: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a DataFrame of 1-minute OHLC data to any given timeframe.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 1-minute OHLC data. \n",
    "      The DataFrame should have a datetime index & columns ['Open', 'High', 'Low', 'Close', 'Volume'].\n",
    "    - timeframe (str): The desired timeframe to resample the data to (e.g., '1H' for 1 hour, '1D' for 1 day).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Resampled DataFrame with OHLC data in the specified timeframe. The index will be renamed to\n",
    "      reflect the new timeframe.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    resampled_df = convert_1m_to_any_timeframe(ohlc_df, '1H')\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame index is of datetime type\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # Try resampling the data to the desired timeframe\n",
    "    try:\n",
    "        df_resampled = df.resample(timeframe).agg({\n",
    "            'Open': 'first',  # Take the first 'Open' value in the timeframe\n",
    "            'High': 'max',    # Take the maximum 'High' value in the timeframe\n",
    "            'Low': 'min',     # Take the minimum 'Low' value in the timeframe\n",
    "            'Close': 'last',  # Take the last 'Close' value in the timeframe\n",
    "            'Volume': 'mean'  # Take the mean 'Volume' value in the timeframe\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while resampling! Error message: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of error\n",
    "\n",
    "    # Rename the index to reflect the new timeframe\n",
    "    df_resampled.index.rename(f'Open time ({timeframe})', inplace = True)\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACD Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_macd(df: pd.DataFrame, short_window: int = 12, long_window: int = 26, signal_window: int = 9) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the MACD (Moving Average Convergence Divergence) for a given DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'Close' price data.\n",
    "    - short_window (int): The window size for the short-term EMA, default is 12.\n",
    "    - long_window (int): The window size for the long-term EMA, default is 26.\n",
    "    - signal_window (int): The window size for the Signal line, default is 9.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with the MACD line and Signal line.\n",
    "    \"\"\"\n",
    "    # Calculate the short-term and long-term EMAs\n",
    "    df['EMA_12'] = df['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "\n",
    "    # Calculate the MACD line\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "\n",
    "    # Calculate the Signal line\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_macd_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on MACD values.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'MACD' and 'Signal_Line' values.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with trading signals.\n",
    "    \"\"\"\n",
    "    df['Signal'] = 0  # Default no signal\n",
    "    df.loc[df['MACD'] > df['Signal_Line'], 'Signal'] = 1  # Buy signal\n",
    "    df.loc[df['MACD'] < df['Signal_Line'], 'Signal'] = -1  # Sell signal\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADX In Combination With Parabolic SAR Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adx(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Average Directional Index (ADX) and add it to the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'High', 'Low', and 'Close' columns.\n",
    "    - window (int): Window size for the ADX calculation (default is 14).\n",
    "    \n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with added 'ADX' column.\n",
    "    \"\"\"\n",
    "    adx = ADXIndicator(df['High'], df['Low'], df['Close'], window=window)\n",
    "    df['ADX'] = adx.adx()\n",
    "    df['DI+'] = adx.adx_pos()\n",
    "    df['DI-'] = adx.adx_neg()\n",
    "    return df\n",
    "\n",
    "def calculate_parabolic_sar(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Parabolic SAR and add it to the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'High', 'Low', and 'Close' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with added 'Parabolic_SAR' column.\n",
    "    \"\"\"\n",
    "    psar = PSARIndicator(df['High'], df['Low'], df['Close'])\n",
    "    df['Parabolic_SAR'] = psar.psar()\n",
    "    return df\n",
    "\n",
    "def generate_adx_parabolic_sar_signals(df: pd.DataFrame, adx_threshold: float = 25) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on ADX and Parabolic SAR.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'ADX' and 'Parabolic_SAR' columns.\n",
    "    - adx_threshold (float): Threshold for ADX to consider a strong trend (default is 25).\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with added 'Signal' column (1 for buy, -1 for sell, 0 for hold).\n",
    "    \"\"\"\n",
    "    df['Signal'] = 0  # Default to hold\n",
    "    df.loc[(df['ADX'] > adx_threshold) & (df['Close'] > df['Parabolic_SAR']), 'Signal'] = 1  # Buy signal\n",
    "    df.loc[(df['ADX'] > adx_threshold) & (df['Close'] < df['Parabolic_SAR']), 'Signal'] = -1  # Sell signal\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSI Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Relative Strength Index (RSI) using the ta library.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'Close' price data.\n",
    "    - window (int): The window size for calculating RSI, default is 14.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with the RSI values.\n",
    "    \"\"\"\n",
    "    # Calculate RSI using ta library\n",
    "    rsi_indicator = RSIIndicator(close=df['Close'], window=window, fillna=True)\n",
    "    df['RSI'] = rsi_indicator.rsi()\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_rsi_signals(df: pd.DataFrame, rsi_lower: int = 30, rsi_upper: int = 70) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on RSI values.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'RSI' values.\n",
    "    - rsi_lower (int): RSI lower threshold for buy signals, default is 30.\n",
    "    - rsi_upper (int): RSI upper threshold for sell signals, default is 70.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with trading signals.\n",
    "    \"\"\"\n",
    "    df['Signal'] = 0  # Default no signal\n",
    "    df.loc[df['RSI'] > rsi_upper, 'Signal'] = -1  # Sell signal\n",
    "    df.loc[df['RSI'] < rsi_lower, 'Signal'] = 1   # Buy signal\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic RSI Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stochrsi(\n",
    "    df: pd.DataFrame,\n",
    "    window: int = 14,\n",
    "    smooth1: int = 3,\n",
    "    smooth2: int = 3,\n",
    "    fillna: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Stochastic RSI (STOCHRSI) for a given DataFrame using the ta library.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'Close' price data.\n",
    "    - window (int): The window size for calculating RSI, default is 14.\n",
    "    - smooth1 (int): The window size for the first smoothing, default is 3.\n",
    "    - smooth2 (int): The window size for the second smoothing, default is 3.\n",
    "    - fillna (bool): The paramter to specify whether to fill NaN values or not.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with the Stochastic RSI values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate Stochastic RSI\n",
    "    stoch_rsi = StochRSIIndicator(\n",
    "        close=df['Close'],\n",
    "        window = window,\n",
    "        smooth1 = smooth1,\n",
    "        smooth2 = smooth2,\n",
    "        fillna = fillna\n",
    "    )\n",
    "\n",
    "    # Add Stochastic RSI values to the DataFrame\n",
    "    df['StochRSI'] = stoch_rsi.stochrsi()\n",
    "    \n",
    "    df['StochRSI_K'] = stoch_rsi.stochrsi_k() * 100\n",
    "    df['StochRSI_D'] = stoch_rsi.stochrsi_d() * 100\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_stochrsi_signals(\n",
    "    df: pd.DataFrame,\n",
    "    stochrsi_upper: int = 0.7,\n",
    "    stochrsi_lower: int = 0.3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Stochastic RSI (STOCHRSI) and generate buy/sell signals for a given DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'Close' price data.\n",
    "    - window (int): The window size for calculating RSI, default is 14.\n",
    "    - smooth1 (int): The window size for the first smoothing, default is 3.\n",
    "    - smooth2 (int): The window size for the second smoothing, default is 3.\n",
    "    - fillna (bool): The parameter to specify whether to fill NaN values or not.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with the Stochastic RSI values and signals.\n",
    "    \"\"\"\n",
    "    # Generate signals\n",
    "    df['Signal'] = 0\n",
    "    df['Signal'] = np.where((df['StochRSI'].shift(1) < 0.2) & (df['StochRSI'] >= 0.2), 1, df['Signal'])  # Buy signal\n",
    "    df['Signal'] = np.where((df['StochRSI'].shift(1) > 0.8) & (df['StochRSI'] <= 0.8), -1, df['Signal'])  # Sell signal\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBV Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_obv(df: pd.DataFrame, fillna: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate On-Balance Volume (OBV) Values.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'Close' and 'Volume' columns.\n",
    "    - fillna (bool): Parameter that specifies whether or not to fill NaN values.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with added 'OBV' column.\n",
    "    \"\"\"\n",
    "    obv = OnBalanceVolumeIndicator(\n",
    "        close = df['Close'],\n",
    "        volume = df['Volume'],\n",
    "        fillna = True\n",
    "    )\n",
    "    \n",
    "    df['OBV'] = obv.on_balance_volume()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_obv_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on On-Balance Volume (OBV) indicator.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'Close' and 'Volume' columns.\n",
    "    - fillna (bool): Parameter that specifies whether or not to fill NaN values.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with added 'OBV' and 'Signal' columns.\n",
    "    \"\"\"\n",
    "    df['Signal'] = 0  # Initialize Signal column\n",
    "    \n",
    "    # Generate signals based on OBV\n",
    "    df.loc[df['OBV'] > df['OBV'].shift(1), 'Signal'] = 1  # Buy signal\n",
    "    df.loc[df['OBV'] < df['OBV'].shift(1), 'Signal'] = -1  # Sell signal\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Moving Average (SMA) Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sma(\n",
    "    df: pd.DataFrame, \n",
    "    window: int, \n",
    "    source: str = 'Close', \n",
    "    offset: int = 0,\n",
    "    fillna: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Simple Moving Average (SMA) for a given DataFrame with additional parameters.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data.\n",
    "    - window (int): The window size for calculating SMA.\n",
    "    - source (str): The column name on which to calculate the SMA, default is 'Close'.\n",
    "    - offset (int): The number of periods to offset the SMA, default is 0.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with the SMA values.\n",
    "    \"\"\"\n",
    "    sma_indicator = SMAIndicator(close = df[source], window = window, fillna = fillna)\n",
    "    df[f'SMA_{window}'] = sma_indicator.sma_indicator()\n",
    "\n",
    "    if offset != 0:\n",
    "        df[f'SMA_{window}'] = df[f'SMA_{window}'].shift(offset)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_sma_signals(\n",
    "    df: pd.DataFrame, \n",
    "    short_window: int = 50, \n",
    "    long_window: int = 200\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on Simple Moving Average (SMA) crossover strategy.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data with SMA values.\n",
    "    - short_window (int): The window size for the short-term SMA, default is 50.\n",
    "    - long_window (int): The window size for the long-term SMA, default is 200.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with trading signals.\n",
    "    \"\"\"\n",
    "    # Calculate short-term and long-term SMAs\n",
    "    df = calculate_sma(df, window=short_window, source='Close')\n",
    "    df = calculate_sma(df, window=long_window, source='Close')\n",
    "    \n",
    "    # Generate signals: \n",
    "    # Buy when the short-term SMA crosses above the long-term SMA\n",
    "    # Sell when the short-term SMA crosses below the long-term SMA\n",
    "    df['Signal'] = 0  # Default no signal\n",
    "    df.loc[df[f'SMA_{short_window}'] > df[f'SMA_{long_window}'], 'Signal'] = 1   # Buy signal\n",
    "    df.loc[df[f'SMA_{short_window}'] < df[f'SMA_{long_window}'], 'Signal'] = -1  # Sell signal\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Moving Average (EMA) Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ema(\n",
    "    df: pd.DataFrame, \n",
    "    window: int, \n",
    "    source: str = 'Close', \n",
    "    offset: int = 0, \n",
    "    fillna: bool = False,\n",
    "    smoothing_line: str = 'ema', \n",
    "    smoothing_length: int = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Exponential Moving Average (EMA) for a given DataFrame with additional parameters.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data.\n",
    "    - window (int): The window size for calculating EMA.\n",
    "    - source (str): The column name on which to calculate the EMA, default is 'Close'.\n",
    "    - offset (int): The number of periods to offset the EMA, default is 0.\n",
    "    - smoothing_line (str): The type of smoothing line, default is 'ema' (only EMA supported in this function).\n",
    "    - smoothing_length (int): The window size for additional smoothing, not used in this function. Will implement later\n",
    "    - fillna (bool): The parameter to specifiy if NaN values are to be filled or not\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with the EMA values.\n",
    "    \"\"\"\n",
    "    if smoothing_line != 'ema':\n",
    "        raise ValueError(\"Only 'ema' smoothing is supported in this function.\")\n",
    "    \n",
    "    ema_indicator = EMAIndicator(close = df[source], window = window, fillna = fillna)\n",
    "    df[f'EMA_{window}'] = ema_indicator.ema_indicator()\n",
    "\n",
    "    if offset != 0:\n",
    "        df[f'EMA_{window}'] = df[f'EMA_{window}'].shift(offset)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_triple_ema_signals(\n",
    "    df: pd.DataFrame, \n",
    "    short_window: int = 5, \n",
    "    medium_window: int = 21, \n",
    "    long_window: int = 50,\n",
    "    source: str = 'Close'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on the Triple EMA Crossover strategy.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data.\n",
    "    - short_window (int): The window size for the short-term EMA.\n",
    "    - medium_window (int): The window size for the medium-term EMA.\n",
    "    - long_window (int): The window size for the long-term EMA.\n",
    "    - source (str): The column name on which to calculate the EMAs, default is 'Close'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with trading signals.\n",
    "    \"\"\"\n",
    "    # Calculate short-term, medium-term, and long-term EMAs\n",
    "    df = calculate_ema(df, short_window, source)\n",
    "    df = calculate_ema(df, medium_window, source)\n",
    "    df = calculate_ema(df, long_window, source)\n",
    "\n",
    "    # Initialize signal column\n",
    "    df['Signal'] = 0\n",
    "\n",
    "    # Buy signal: Short EMA crosses above both Medium and Long EMAs\n",
    "    df.loc[(df[f'EMA_{short_window}'] > df[f'EMA_{medium_window}']) & (df[f'EMA_{short_window}'] > df[f'EMA_{long_window}']), 'Signal'] = 1\n",
    "\n",
    "    # Sell signal: Short EMA crosses below both Medium and Long EMAs\n",
    "    df.loc[(df[f'EMA_{short_window}'] < df[f'EMA_{medium_window}']) & (df[f'EMA_{short_window}'] < df[f'EMA_{long_window}']), 'Signal'] = -1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing Moving Average (SMMA) Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smma(\n",
    "    df: pd.DataFrame, \n",
    "    window: int, \n",
    "    source: str = 'Close', \n",
    "    offset: int = 0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Smoothed Moving Average (SMMA) for a given DataFrame with additional parameters.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data.\n",
    "    - window (int): The window size for calculating SMMA.\n",
    "    - source (str): The column name on which to calculate the SMMA, default is 'Close'.\n",
    "    - offset (int): The number of periods to offset the SMMA, default is 0.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with the SMMA values.\n",
    "    \"\"\"\n",
    "    # Initialize SMMA column\n",
    "    df['SMMA'] = 0.0\n",
    "\n",
    "    # Calculate initial SMMA values (SMA for the first window periods)\n",
    "    df['SUM1'] = df[source].rolling(window=window, min_periods=1).sum()\n",
    "    df.loc[df.index[window - 1], 'SMMA'] = df['SUM1'].iloc[window - 1] / window\n",
    "\n",
    "    # Calculate subsequent SMMA values using the iterative formula\n",
    "    for i in range(window, len(df)):\n",
    "        prev_smma = df.loc[df.index[i - 1], 'SMMA']\n",
    "        current_price = df.loc[df.index[i], source]\n",
    "        df.loc[df.index[i], 'SMMA'] = (prev_smma * (window - 1) + current_price) / window\n",
    "\n",
    "    # Drop intermediate columns if not needed\n",
    "    df.drop(['SUM1'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_smma_signals(\n",
    "    df: pd.DataFrame, \n",
    "    window: int = 14, \n",
    "    source: str = 'Close'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on the Smoothed Moving Average (SMMA) crossover strategy.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data.\n",
    "    - window (int): The window size for calculating SMMA.\n",
    "    - source (str): The column name on which to calculate the SMMA, default is 'Close'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with trading signals.\n",
    "    \"\"\"\n",
    "    # Calculate SMMA\n",
    "    df = calculate_smma(df, window, source)\n",
    "\n",
    "    # Initialize signal column\n",
    "    df['Signal'] = 0\n",
    "\n",
    "    # Buy signal: When price crosses above SMMA\n",
    "    df.loc[df[source] > df['SMMA'], 'Signal'] = 1\n",
    "\n",
    "    # Sell signal: When price crosses below SMMA\n",
    "    df.loc[df[source] < df['SMMA'], 'Signal'] = -1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume Weighted Moving Average (VWMA) Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vwma(df: pd.DataFrame, window: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Volume Weighted Moving Average (VWMA) for a given DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data and volume.\n",
    "    - window (int): The window size for calculating VWMA.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with the VWMA values.\n",
    "    \"\"\"\n",
    "    df['PriceVolume'] = df['Close'] * df['Volume']\n",
    "    df['CumulativePriceVolume'] = df['PriceVolume'].rolling(window=window, min_periods=1).sum()\n",
    "    df['CumulativeVolume'] = df['Volume'].rolling(window=window, min_periods=1).sum()\n",
    "    df[f'VWMA_{window}'] = df['CumulativePriceVolume'] / df['CumulativeVolume']\n",
    "\n",
    "    # Drop intermediate columns if not needed\n",
    "    df.drop(['PriceVolume', 'CumulativePriceVolume', 'CumulativeVolume'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_vwma_signals(df: pd.DataFrame, short_window: int = 10, long_window: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on VWMA crossover strategy.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing price data and volume.\n",
    "    - short_window (int): Window size for short-term VWMA.\n",
    "    - long_window (int): Window size for long-term VWMA.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with VWMA values and trading signals.\n",
    "    \"\"\"\n",
    "    # Calculate short-term VWMA\n",
    "    df = calculate_vwma(df, window=short_window)\n",
    "    df.rename(columns={f'VWMA_{short_window}': 'VWMA_Short'}, inplace=True)\n",
    "\n",
    "    # Calculate long-term VWMA\n",
    "    df = calculate_vwma(df, window=long_window)\n",
    "    df.rename(columns={f'VWMA_{long_window}': 'VWMA_Long'}, inplace=True)\n",
    "\n",
    "    # Generate trading signals\n",
    "    df['Signal'] = 0\n",
    "    df['Signal'] = df.apply(lambda row: 1 if row['VWMA_Short'] > row['VWMA_Long'] else (-1 if row['VWMA_Short'] < row['VWMA_Long'] else 0), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome Oscillator Indicator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_AO(df: pd.DataFrame, fillna: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate On-Balance Volume (OBV) Values.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'Close' and 'Volume' columns.\n",
    "    - fillna (bool): Parameter that specifies whether or not to fill NaN values.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with added 'OBV' column.\n",
    "    \"\"\"\n",
    "    obv = AwesomeOscillatorIndicator(\n",
    "        high = df['High'],\n",
    "        low = df['Low'],\n",
    "        fillna = True\n",
    "    )\n",
    "    \n",
    "    df['AO'] = obv.awesome_oscillator()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_AO_signals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals based on Awesome Oscillator (AO) values.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'AO' column. Should have a datetime index.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame): DataFrame with added 'Signal' column indicating Buy (1), Sell (-1), or Hold (0) signals.\n",
    "    \"\"\"\n",
    "    # Initialize Signal column with zeros\n",
    "    df['Signal'] = 0\n",
    "    \n",
    "    # Generate signals based on AO\n",
    "    for i in range(1, len(df)):\n",
    "        if df['AO'].iloc[i] > 0 and df['AO'].iloc[i-1] <= 0:\n",
    "            df.at[df.index[i], 'Signal'] = 1  # Buy signal\n",
    "        elif df['AO'].iloc[i] < 0 and df['AO'].iloc[i-1] >= 0:\n",
    "            df.at[df.index[i], 'Signal'] = -1  # Sell signal\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting Function: Previous Week's Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_backtest_df(data, data_1m, df_for_freq_inferring, initial_balance=1000, transaction_fee=0.01):\n",
    "    \"\"\"\n",
    "    Generate a backtesting DataFrame based on MACD signals.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing historical data with columns:\n",
    "                             'Open time (4H)', 'Open', 'High', 'Low', 'Close', 'Volume', 'MACD_Signal'.\n",
    "                             The DataFrame must have 'Open time (4H)' as a DateTime index.\n",
    "        data_1m (pd.DataFrame): DataFrame containing 1-minute interval data with 'Open' prices.\n",
    "        initial_balance (float): Initial balance for the backtest.\n",
    "        transaction_fee (float): Transaction fee as a percentage of the current balance for each trade.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the backtesting results with columns:\n",
    "                      'Open time (4H)', 'direction', 'entry price', 'close price', 'PNL', 'Balance'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def find_first_change(signal):\n",
    "        # Convert the list to a numpy array\n",
    "        signal_array = np.array(signal)\n",
    "\n",
    "        # Find indices of non-zero elements\n",
    "        non_zero_indices = np.flatnonzero(signal_array != 0)\n",
    "\n",
    "        # Find where the value changes\n",
    "        changes = np.where(np.diff(signal_array[non_zero_indices]))[0] + 1\n",
    "        changes = np.insert(changes, 0, 0)\n",
    "        \n",
    "        if len(non_zero_indices) < 1:\n",
    "            return signal.index[0], signal.index[-1]\n",
    "\n",
    "        if len(changes) == 1:\n",
    "            # Get the indices of the first change\n",
    "            first_change_start = non_zero_indices[changes[0]]\n",
    "            first_change_end = None\n",
    "        else:\n",
    "            # Get the indices of the first change\n",
    "            first_change_start = non_zero_indices[changes[0]]\n",
    "            first_change_end = non_zero_indices[changes[0 + 1]]\n",
    "\n",
    "        # Get the starting and ending time of the direction change\n",
    "        trade_start_time = signal.index[first_change_start]\n",
    "        if first_change_end != None:\n",
    "            trade_end_time = signal.index[first_change_end]\n",
    "        else:\n",
    "            trade_end_time = None\n",
    "\n",
    "        # Return the start and end time tuple\n",
    "        return (trade_start_time, trade_end_time)\n",
    "    \n",
    "    # For index name\n",
    "    index_name = data.index.name\n",
    "\n",
    "    # For timeframe\n",
    "    time_frame = pd.infer_freq(df_for_freq_inferring.index)\n",
    "\n",
    "    # If timeframe is like 'H' or 'D' or 'Y' then append 1 for specificity\n",
    "    if len(time_frame) == 1:\n",
    "        time_frame = '1' + time_frame\n",
    "\n",
    "    # Extract necessary columns as numpy arrays\n",
    "    high_prices_1m = data_1m['High']\n",
    "    low_prices_1m = data_1m['Low']\n",
    "    open_prices_1m = data_1m['Open']\n",
    "    open_prices = data['Open']\n",
    "    signals = data['Signal']\n",
    "    \n",
    "    # Initialize the exit indices for tp or sl hit (takes the lowest: which happened first)\n",
    "    exit_index_tp = None\n",
    "    exit_index_sl = None\n",
    "    \n",
    "    # Initialize the backtest results array\n",
    "    backtest_data = []\n",
    "\n",
    "    # Initialize trade parameters\n",
    "    tp = 0.05  # 5% take profit\n",
    "    sl = 0.03  # 3% stop loss\n",
    "    \n",
    "    # Initialize the balance\n",
    "    balance = initial_balance\n",
    "    \n",
    "    # Get last date\n",
    "    last_date = signals.index[-1]\n",
    "    \n",
    "    # Initializing List To Store Directions For The Trade\n",
    "    directions = []\n",
    "    \n",
    "    # Iterate\n",
    "    while(True):\n",
    "        trade_start_time, trade_end_time = find_first_change(signals)\n",
    "\n",
    "        if trade_end_time == None:\n",
    "            break\n",
    "            \n",
    "        direction_start = 'long' if signals[trade_start_time] == 1 else 'short'\n",
    "        direction_end = 'long' if signals[trade_end_time] == 1 else 'short'\n",
    "        entry_price = open_prices[trade_start_time]\n",
    "        \n",
    "        # Calculate take profit and stop loss prices\n",
    "        if direction_start == 'long':\n",
    "            tp_price = entry_price * (1 + tp)\n",
    "            sl_price = entry_price * (1 - sl)\n",
    "        else:\n",
    "            tp_price = entry_price * (1 - tp)\n",
    "            sl_price = entry_price * (1 + sl)\n",
    "        \n",
    "        # Find the exit point for the trade\n",
    "        exit_index = None\n",
    "        action = 'direction'  # Default action is direction change\n",
    "        \n",
    "        # getting to the closest time of that interval\n",
    "        # Assuming trade_end_time is a datetime object\n",
    "        # Basically doing this, so the tp and sl hit only checks and\n",
    "        # compares from the (T + 1)th time till the trade end time.\n",
    "        trade_start_time_matching = pd.to_datetime(trade_start_time)\n",
    "        add_minute = pd.Timedelta('1m')\n",
    "        trade_start_time_matching = trade_start_time_matching + add_minute\n",
    "        \n",
    "        if direction_start == 'long':\n",
    "            tp_hit = np.where(high_prices_1m[trade_start_time_matching:trade_end_time] >= tp_price)[0]\n",
    "            sl_hit = np.where(low_prices_1m[trade_start_time_matching:trade_end_time] <= sl_price)[0]\n",
    "        else:\n",
    "            tp_hit = np.where(low_prices_1m[trade_start_time_matching:trade_end_time] <= tp_price)[0]\n",
    "            sl_hit = np.where(high_prices_1m[trade_start_time_matching:trade_end_time] >= sl_price)[0]\n",
    "\n",
    "        if len(tp_hit) > 0:\n",
    "            exit_index = tp_hit[0]\n",
    "            action = 'tp'\n",
    "        if len(sl_hit) > 0 and (len(tp_hit) == 0 or sl_hit[0] < tp_hit[0]):\n",
    "            exit_index = sl_hit[0]\n",
    "            action = 'sl'\n",
    "            \n",
    "        if action == 'direction':\n",
    "            close_price = open_prices[trade_end_time]\n",
    "        else:\n",
    "            if action == 'tp':\n",
    "                if direction_start == 'long':\n",
    "                    trade_end_time = high_prices_1m[trade_start_time_matching:trade_end_time].index[exit_index]\n",
    "                    close_price = high_prices_1m[trade_end_time]\n",
    "                else:\n",
    "                    trade_end_time = low_prices_1m[trade_start_time_matching:trade_end_time].index[exit_index]\n",
    "                    close_price = low_prices_1m[trade_end_time]\n",
    "            else:\n",
    "                if direction_start == 'long':\n",
    "                    trade_end_time = low_prices_1m[trade_start_time_matching:trade_end_time].index[exit_index]\n",
    "                    close_price = low_prices_1m[trade_end_time]\n",
    "                else:\n",
    "                    trade_end_time = high_prices_1m[trade_start_time_matching:trade_end_time].index[exit_index]\n",
    "                    close_price = high_prices_1m[trade_end_time]\n",
    "                    \n",
    "            if len(directions) != 0:\n",
    "                direction_end = directions[-1]\n",
    "                direction_start = directions[-1]\n",
    "        \n",
    "        # Record the trade entry and exit\n",
    "        backtest_data.append([trade_start_time, direction_start, entry_price, 0, None])\n",
    "        backtest_data.append([trade_end_time, direction_end, entry_price, close_price, action])\n",
    "            \n",
    "        # getting to the closest time of that interval\n",
    "        # Assuming trade_end_time is a datetime object\n",
    "        trade_end_time = pd.to_datetime(trade_end_time)\n",
    "\n",
    "        # Define the time format\n",
    "        time_format = pd.Timedelta(time_frame)\n",
    "\n",
    "        # Calculate the remainder when trade_end_time is divided by time_format\n",
    "        remainder = trade_end_time.to_numpy().astype('datetime64[ns]').astype(np.int64) % time_format.to_numpy().astype('timedelta64[ns]').astype(np.int64)\n",
    "\n",
    "        # If remainder is not zero, round up to the next multiple of time_format\n",
    "        if remainder != 0:\n",
    "            trade_end_time = trade_end_time + (time_format - pd.Timedelta(remainder, unit='ns'))\n",
    "            \n",
    "        # This is the condition that would end the loop (else it would run infinitely)\n",
    "        if trade_end_time >= last_date:\n",
    "            break\n",
    "            \n",
    "        signals = signals[trade_end_time:]\n",
    "        \n",
    "        directions.append(direction_start)\n",
    "        directions.append(direction_end)\n",
    "\n",
    "    # If no signal change detected in the entire signal array, return empty dataframe (for error handling)\n",
    "    if not backtest_data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    backtest_df = pd.DataFrame(backtest_data, columns=[index_name, 'direction', 'entry price', 'close price', 'action'])\n",
    "\n",
    "    # Calculate PNL using vectorized operations\n",
    "    entry_prices = backtest_df['entry price'][1::2].values\n",
    "    close_prices = backtest_df['close price'][1::2].values\n",
    "    directions = backtest_df['direction'][0:-1:2].values\n",
    "\n",
    "    pnl = np.where(directions == 'long',\n",
    "                   ((close_prices - entry_prices) / entry_prices) * 100,\n",
    "                   ((entry_prices - close_prices) / entry_prices) * 100)\n",
    "\n",
    "    # Insert the PNL values back into the DataFrame\n",
    "    backtest_df.loc[1::2, 'PNL'] = pnl\n",
    "\n",
    "    # Update balance considering PNL and transaction fees\n",
    "    balances = [initial_balance]\n",
    "    for pnl_value in pnl:\n",
    "        transaction_cost = balances[-1] * (transaction_fee / 100)\n",
    "        new_balance = balances[-1] + (np.abs(balances[-1]) * (pnl_value / 100)) - transaction_cost\n",
    "        balances.append(new_balance)\n",
    "    \n",
    "    # Insert the balance values back into the DataFrame\n",
    "    backtest_df['Balance'] = pd.Series(np.repeat(balances[1:], 2)[:len(backtest_df)])\n",
    "\n",
    "    # Setting the date as the index of the dataframe\n",
    "    backtest_df.set_index(index_name, inplace = True)\n",
    "    backtest_df.index = pd.to_datetime(backtest_df.index, format='mixed')\n",
    "\n",
    "    return backtest_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function For Stats Calculation (Changed Alot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last row of all pnl scores\n",
    "def get_last_pnl_scores(ledger):\n",
    "    # List of columns to extract\n",
    "    pnl_cols = ['pnl_sum_1', 'pnl_sum_7', 'pnl_sum_15', 'pnl_sum_30', 'pnl_sum_45', 'pnl_sum_60']\n",
    "    last_values = ledger[pnl_cols].iloc[-1].values\n",
    "    \n",
    "    return last_values.tolist()\n",
    "\n",
    "# Calculate the 1d, 7d, 15d, 30d, 45d, 60d PNL scores\n",
    "def calculate_pnl_sum_all(df):\n",
    "    date_column = df.columns[0]\n",
    "    \n",
    "    # Ensure the date column is in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
    "    \n",
    "    # Ensure the PNL column is numeric and handle any non-numeric values\n",
    "    df['PNL'] = pd.to_numeric(df['PNL'], errors='coerce').fillna(0.0)\n",
    "    \n",
    "    # Adding the cumulative sum column to the dataframe\n",
    "    df['pnl_sum'] = df['PNL'].cumsum()\n",
    "    \n",
    "    # Precompute the time deltas\n",
    "    time_deltas = {\n",
    "        'pnl_sum_1': timedelta(days=1),\n",
    "        'pnl_sum_7': timedelta(days=7),\n",
    "        'pnl_sum_15': timedelta(days=15),\n",
    "        'pnl_sum_30': timedelta(days=30),\n",
    "        'pnl_sum_45': timedelta(days=45),\n",
    "        'pnl_sum_60': timedelta(days=60)\n",
    "    }\n",
    "    \n",
    "    # Initialize columns with NaN values\n",
    "    for col_name in time_deltas.keys():\n",
    "        df[col_name] = np.nan\n",
    "    \n",
    "    # Set the date column as the index\n",
    "    df.set_index(date_column, inplace=True)\n",
    "    \n",
    "    for col_name, delta in time_deltas.items():\n",
    "        window_days = delta.days\n",
    "        # Calculate the rolling sum with a time-based window\n",
    "        rolling_sums = df['PNL'].rolling(window=f'{window_days}D', closed='both').sum()\n",
    "        \n",
    "        # Align rolling sums with the original DataFrame\n",
    "        df[col_name] = rolling_sums.reindex(df.index).fillna(0.0)\n",
    "    \n",
    "    # Reset index to get date column back\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # Round the results to 2 decimal places\n",
    "    df = df.round({col: 2 for col in time_deltas.keys()})\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate the difference of date\n",
    "def calculate_diff_date(start, end):\n",
    "    return (end - start).days\n",
    "\n",
    "# calculate drawdown longest drawdown,current drawdown\n",
    "def longest_drawdown(pnl_cum_list, date):\n",
    "    max_drawdown = 0\n",
    "    max_drawdown_duration = 0\n",
    "    curr_drawdown = 0\n",
    "    curr_drawdown_duration = 0\n",
    "    drawdown_durations = []\n",
    "\n",
    "    maxPnl = pnl_cum_list[0]\n",
    "    start_date = None\n",
    "    drawdown_active = False\n",
    "\n",
    "    for counter, value in enumerate(pnl_cum_list):\n",
    "        if value < maxPnl:\n",
    "            drawdown = maxPnl - value\n",
    "\n",
    "            if not drawdown_active:\n",
    "                start_date = date.iloc[counter]  # Use iloc to access by position\n",
    "                drawdown_active = True\n",
    "\n",
    "            curr_drawdown = drawdown\n",
    "            curr_drawdown_duration = calculate_diff_date(start_date, date.iloc[counter])  # Use iloc\n",
    "\n",
    "            if curr_drawdown_duration > max_drawdown_duration:\n",
    "                max_drawdown_duration = curr_drawdown_duration\n",
    "\n",
    "            if drawdown > max_drawdown:\n",
    "                max_drawdown = drawdown\n",
    "\n",
    "        elif drawdown_active:\n",
    "            end_date = date.iloc[counter]  # Use iloc\n",
    "            drawdown_durations.append(calculate_diff_date(start_date, end_date))\n",
    "            drawdown_active = False\n",
    "            start_date = None  # Reset start_date after the drawdown ends\n",
    "            curr_drawdown_duration = 0  # Reset current drawdown duration\n",
    "            maxPnl = value\n",
    "\n",
    "        if value > maxPnl:\n",
    "            maxPnl = value\n",
    "\n",
    "    # Ensure the current drawdown duration is updated correctly\n",
    "    if drawdown_active:\n",
    "        curr_drawdown_duration = calculate_diff_date(start_date, date.iloc[-1])  # Use iloc\n",
    "\n",
    "    return drawdown_durations, round(max_drawdown, 2), max_drawdown_duration, round(curr_drawdown, 2), curr_drawdown_duration\n",
    "\n",
    "# Calculate drawdown\n",
    "def calculate_drawdown(pnl_cum_list):\n",
    "    drawdown_list = []\n",
    "    maxPnl = pnl_cum_list[0]\n",
    "\n",
    "    for value in pnl_cum_list:\n",
    "        maxPnl = max(maxPnl, value)\n",
    "        drawdown = round(value - maxPnl, 2)\n",
    "        drawdown_list.append(drawdown)\n",
    "\n",
    "    return drawdown_list\n",
    "\n",
    "# win/losses calculation\n",
    "def calculate_wins_losses(df):\n",
    "    total_wins = total_losses = consecutive_wins = consecutive_losses = 0\n",
    "    temp_wins = temp_losses = 0\n",
    "\n",
    "    for pnl in df['PNL'][1:]:\n",
    "        if pnl > 0:\n",
    "            total_wins += 1\n",
    "            temp_wins += 1\n",
    "            if temp_losses > consecutive_losses:\n",
    "                consecutive_losses = temp_losses\n",
    "            temp_losses = 0\n",
    "        elif pnl < 0:\n",
    "            total_losses += 1\n",
    "            temp_losses += 1\n",
    "            if temp_wins > consecutive_wins:\n",
    "                consecutive_wins = temp_wins\n",
    "            temp_wins = 0\n",
    "\n",
    "    win_percentage = round(total_wins / (total_wins + total_losses) * 100, 2)\n",
    "    loss_percentage = round(total_losses / (total_wins + total_losses) * 100, 2)\n",
    "\n",
    "    return total_wins, total_losses, consecutive_wins, consecutive_losses, win_percentage, loss_percentage\n",
    "    \n",
    "# Calculate r2 score\n",
    "def calculate_r2_score(ledger):\n",
    "    y = ledger.pnl_sum.to_numpy()\n",
    "    x = np.arange(len(y))\n",
    "    \n",
    "    # Mean of x and y\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    \n",
    "    # Centered variables\n",
    "    x_centered = x - x_mean\n",
    "    y_centered = y - y_mean\n",
    "    \n",
    "    # Covariance of x and y\n",
    "    covariance = np.sum(x_centered * y_centered)\n",
    "    \n",
    "    # Variance of x and y\n",
    "    variance_x = np.sum(x_centered ** 2)\n",
    "    variance_y = np.sum(y_centered ** 2)\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = covariance / np.sqrt(variance_x * variance_y)\n",
    "    \n",
    "    # Calculate R^2 score\n",
    "    r2 = correlation ** 2\n",
    "    \n",
    "    return round(r2, 2)\n",
    "\n",
    "# positive negative pnl calculation\n",
    "def pos_neg_pnl_percent(pnl_percent):\n",
    "    # Negative PnL sum directly from filtering\n",
    "    total_neg_pnl_percent = pnl_percent[pnl_percent < 0].sum()\n",
    "    # total_neg_pnl_percent = neg_pnl_percent.sum()\n",
    "\n",
    "    # Positive PnL sum directly from filtering\n",
    "    total_pos_pnl_percent = pnl_percent[pnl_percent > 0].sum()\n",
    "\n",
    "    # Total PnL percent (no need to store intermediate results)\n",
    "    return total_neg_pnl_percent + total_pos_pnl_percent, total_neg_pnl_percent, total_pos_pnl_percent\n",
    "\n",
    "# sharp calculation\n",
    "def calculate_sharpe(returns):\n",
    "    # Calculate the sharpe ratio using QuantStats library with risk free rate = 0 (2nd parameter)\n",
    "    sharpe_ratio = qs.stats.sharpe(returns, 0)\n",
    "\n",
    "    return round(sharpe_ratio,2)\n",
    "\n",
    "# Calculate downside risk\n",
    "def calculate_downside_risk(returns, risk_free=0):\n",
    "    # Calculate adjusted returns by subtracting the risk-free rate\n",
    "    adj_returns = returns - risk_free\n",
    "    \n",
    "    # Calculate squared downside risk\n",
    "    sqr_downside = np.square(np.minimum(adj_returns, 0))\n",
    "    \n",
    "    # Calculate the mean of the squared downside and scale it by 252 (annualization factor)\n",
    "    mean_sqr_downside = np.nanmean(sqr_downside)\n",
    "    \n",
    "    # Return the square root of the annualized downside risk\n",
    "    return np.sqrt(mean_sqr_downside * 252)\n",
    "\n",
    "# Calculate sortino\n",
    "def calculate_sortino(returns):\n",
    "    # Calculate the sortino using QuantStats library\n",
    "    sortino=qs.stats.sortino(returns)\n",
    "    \n",
    "    return sortino\n",
    "\n",
    "# Calculate average daily pnl\n",
    "def average_daily_pnl(pnl_sum, date_started):\n",
    "    # Ensure date_started is in datetime format\n",
    "    if isinstance(date_started, str):\n",
    "        date_started = datetime.strptime(date_started, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Calculate the number of days between date_started and now\n",
    "    delta = (datetime.now() - date_started).days\n",
    "    \n",
    "    # Calculate the average daily PnL\n",
    "    daily_pnl = pnl_sum / delta\n",
    "    \n",
    "    return daily_pnl\n",
    "\n",
    "# Caculate win / loss ratio\n",
    "def calculate_win_loss_ratio(win_percentage, loss_percentage):\n",
    "    # Handle division by zero by returning the win_percentage if loss_percentage is 0\n",
    "    if loss_percentage == 0:\n",
    "        return win_percentage\n",
    "    \n",
    "    # Calculate and return the win/loss ratio\n",
    "    return win_percentage / loss_percentage\n",
    "\n",
    "# Calculate alpha beta\n",
    "def calculate_alpha_beta(df):\n",
    "    # Convert necessary columns to NumPy arrays for faster computation\n",
    "    close_price = df['close price'].astype(float).values\n",
    "    entry_price = df['entry price'].astype(float).values\n",
    "    pnl = df['PNL'].astype(float).values\n",
    "    \n",
    "    # Calculate btc_return using vectorized operations\n",
    "    btc_return = (close_price / entry_price - 1) * 100\n",
    "    \n",
    "    # Linear regression using NumPy\n",
    "    # Add a constant term (intercept) to the predictor\n",
    "    X = np.vstack((pnl, np.ones_like(pnl))).T\n",
    "    Y = btc_return\n",
    "    \n",
    "    # Solve for alpha (slope) and beta (intercept)\n",
    "    coefficients = np.linalg.lstsq(X, Y, rcond=None)[0]\n",
    "    \n",
    "    # Coefficients[0] = alpha, Coefficients[1] = beta\n",
    "    return coefficients[0], coefficients[1]\n",
    "\n",
    "# Calculate all statistics\n",
    "def calculate_all_statistics(strat_ledger):\n",
    "    # Get the name of the date column from dataframe\n",
    "    date_column = strat_ledger.columns[0]\n",
    "\n",
    "    # Adding the pnl_sum column to the dataframe\n",
    "    strat_ledger['pnl_sum'] = strat_ledger['PNL'].cumsum()\n",
    "    \n",
    "    # Calculate drawdown\n",
    "    drawdown_list = calculate_drawdown(strat_ledger['pnl_sum'])\n",
    "    \n",
    "    # Calculate PnL sums for different periods\n",
    "    pnl_sum_scores = get_last_pnl_scores(strat_ledger)\n",
    "    \n",
    "    # Calculate the total PnL percent, total positive and total negative pnl percent as well\n",
    "    # total_pnl_percent = strat_ledger['PNL'].sum()\n",
    "    total_pnl_percent, total_neg_pnl_percent, total_pos_pnl_percent = pos_neg_pnl_percent(strat_ledger['PNL'])\n",
    "\n",
    "    # Calculate win/loss statistics\n",
    "    total_wins, total_losses, consecutive_wins, consecutive_losses, win_percentage, loss_percentage = calculate_wins_losses(strat_ledger)\n",
    "    win_loss_ratio = calculate_win_loss_ratio(win_percentage, loss_percentage)\n",
    "    \n",
    "    # Calculate average daily PnL\n",
    "    current_pnl_sum = strat_ledger['pnl_sum'].iloc[-1]\n",
    "    date_started = pd.to_datetime(strat_ledger[date_column].iloc[0])\n",
    "    avg_daily_pnl = average_daily_pnl(current_pnl_sum, date_started)\n",
    "    \n",
    "    # Filter dataframe for non-zero close price\n",
    "    temp_df = strat_ledger[strat_ledger['close price'] != 0]\n",
    "    \n",
    "    # Calculate alpha and beta\n",
    "    alpha, beta = calculate_alpha_beta(temp_df)\n",
    "    \n",
    "    # Calculate Sharpe and Sortino ratios\n",
    "    sharpe = calculate_sharpe(temp_df['PNL'])\n",
    "    sortino = calculate_sortino(temp_df['PNL'])\n",
    "\n",
    "    # Calculate r2 score\n",
    "    r2_score = calculate_r2_score(strat_ledger)\n",
    "    \n",
    "    # Calculate downside risk\n",
    "    downside_risk = calculate_downside_risk(temp_df['PNL'])\n",
    "    \n",
    "    # Calculate drawdown statistics\n",
    "    drawdown_durations, max_drawdown, max_drawdown_duration, curr_drawdown, curr_drawdown_duration = longest_drawdown(\n",
    "        strat_ledger['pnl_sum'], strat_ledger[date_column]\n",
    "    )\n",
    "    average_drawdown = round(np.mean(drawdown_list), 2) if drawdown_list else 0\n",
    "    average_drawdown_duration = round(np.mean(drawdown_durations), 2) if drawdown_durations else 0\n",
    "    \n",
    "    # Create a dictionary with descriptive keys\n",
    "    stats_dict = {\n",
    "        date_column: strat_ledger[date_column].iloc[-1],\n",
    "        'Current Drawdown': -round(float(abs(curr_drawdown)), 2),\n",
    "        'Current Drawdown Duration (days)': round(float(curr_drawdown_duration), 2),\n",
    "        'Average Drawdown': -round(float(abs(average_drawdown)), 2),\n",
    "        'Average Drawdown Duration (days)': round(float(average_drawdown_duration), 2),\n",
    "        'Maximum Drawdown': -round(float(abs(max_drawdown)), 2),\n",
    "        'Maximum Drawdown Duration (days)': round(float(max_drawdown_duration), 2),\n",
    "        'R-squared Score': round(float(r2_score), 2),\n",
    "        'Sharpe Ratio': round(float(sharpe), 2),\n",
    "        'Sortino Ratio': round(float(sortino), 2),\n",
    "        'Total PnL (%)': round(float(total_pnl_percent), 2),\n",
    "        'Total Positive PnL (%)': round(float(total_pos_pnl_percent), 2),\n",
    "        'Total Negative PnL (%)': round(float(total_neg_pnl_percent), 2),\n",
    "        'Total Wins': round(float(total_wins), 2),\n",
    "        'Total Losses': round(float(total_losses), 2),\n",
    "        'Consecutive Wins': round(float(consecutive_wins), 2),\n",
    "        'Consecutive Losses': round(float(consecutive_losses), 2),\n",
    "        'Win Percentage (%)': round(float(win_percentage), 2),\n",
    "        'Loss Percentage (%)': round(float(loss_percentage), 2),\n",
    "        'PnL Sum 1': round(float(pnl_sum_scores[0]), 2),\n",
    "        'PnL Sum 7': round(float(pnl_sum_scores[1]), 2),\n",
    "        'PnL Sum 15': round(float(pnl_sum_scores[2]), 2),\n",
    "        'PnL Sum 30': round(float(pnl_sum_scores[3]), 2),\n",
    "        'PnL Sum 45': round(float(pnl_sum_scores[4]), 2),\n",
    "        'PnL Sum 60': round(float(pnl_sum_scores[5]), 2),\n",
    "        'Average Daily PnL': round(float(avg_daily_pnl), 2),\n",
    "        'Win/Loss Ratio': round(float(win_loss_ratio), 2),\n",
    "        'Alpha': round(float(alpha), 2),\n",
    "        'Beta': round(float(beta), 2),\n",
    "        'Downside Risk': round(float(downside_risk), 2),\n",
    "    }\n",
    "\n",
    "    # Convert dictionary to DataFrame for better visualization (optional)\n",
    "    stats_df = pd.DataFrame([stats_dict])\n",
    "\n",
    "    stats_df.set_index(date_column, inplace = True)\n",
    "\n",
    "    # Convert the index to datetime format\n",
    "    stats_df.index = pd.to_datetime(stats_df.index)\n",
    "    \n",
    "    print(f'{colors.GREEN}All stats calculated!{colors.RESET}')\n",
    "\n",
    "    return stats_dict, stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading The Previously Saved Data For BTCUSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    BTCUSDT_Filtered_data_1M_last_month = pd.read_csv(get_csv_tail(full_csv_path_1, max_rows=85165), usecols = ['Open time (1M)', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "    BTCUSDT_Filtered_data_1M_last_month.set_index('Open time (1M)', inplace = True)\n",
    "    \n",
    "    # Convert the index to datetime format\n",
    "    BTCUSDT_Filtered_data_1M_last_month.index = pd.to_datetime(BTCUSDT_Filtered_data_1M_last_month.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (1M)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:47:00</th>\n",
       "      <td>66519.3</td>\n",
       "      <td>66519.3</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>1.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:48:00</th>\n",
       "      <td>66519.3</td>\n",
       "      <td>66519.3</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>66490.5</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:49:00</th>\n",
       "      <td>66490.6</td>\n",
       "      <td>66519.2</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>1.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:50:00</th>\n",
       "      <td>66492.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>66492.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>2.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:51:00</th>\n",
       "      <td>66500.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>66492.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>3.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:43:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:44:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>1.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:45:00</th>\n",
       "      <td>64438.2</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:46:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.0</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.2</td>\n",
       "      <td>1.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:47:00</th>\n",
       "      <td>64280.2</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.2</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>1.430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43201 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "Open time (1M)                                                 \n",
       "2024-06-18 03:47:00  66519.3  66519.3  66490.0  66490.0   1.022\n",
       "2024-06-18 03:48:00  66519.3  66519.3  66490.0  66490.5   0.762\n",
       "2024-06-18 03:49:00  66490.6  66519.2  66490.0  66490.0   1.298\n",
       "2024-06-18 03:50:00  66492.0  66500.0  66492.0  66500.0   2.510\n",
       "2024-06-18 03:51:00  66500.0  66500.0  66492.0  66500.0   3.236\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2024-07-18 03:43:00  64280.1  64280.1  64280.1  64280.1   0.000\n",
       "2024-07-18 03:44:00  64280.1  64438.2  64280.1  64280.1   1.505\n",
       "2024-07-18 03:45:00  64438.2  64438.2  64280.1  64438.2   0.053\n",
       "2024-07-18 03:46:00  64280.1  64438.0  64280.1  64280.2   1.544\n",
       "2024-07-18 03:47:00  64280.2  64438.2  64280.2  64438.2   1.430\n",
       "\n",
       "[43201 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTCUSDT_Filtered_data_1M_last_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTCUSDT_Filtered_data_1M_last_month_1st = BTCUSDT_Filtered_data_1M_last_month[:29779].copy()\n",
    "BTCUSDT_Filtered_data_1M_last_month_2nd = BTCUSDT_Filtered_data_1M_last_month[29779:-1].copy()\n",
    "BTCUSDT_Filtered_data_1M_last = BTCUSDT_Filtered_data_1M_last_month[-1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (1M)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:47:00</th>\n",
       "      <td>66519.3</td>\n",
       "      <td>66519.3</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>1.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:48:00</th>\n",
       "      <td>66519.3</td>\n",
       "      <td>66519.3</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>66490.5</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:49:00</th>\n",
       "      <td>66490.6</td>\n",
       "      <td>66519.2</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>66490.0</td>\n",
       "      <td>1.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:50:00</th>\n",
       "      <td>66492.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>66492.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>2.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-18 03:51:00</th>\n",
       "      <td>66500.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>66492.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>3.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:01:00</th>\n",
       "      <td>56612.0</td>\n",
       "      <td>56612.0</td>\n",
       "      <td>56200.0</td>\n",
       "      <td>56309.4</td>\n",
       "      <td>5.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:02:00</th>\n",
       "      <td>56256.8</td>\n",
       "      <td>56814.0</td>\n",
       "      <td>56159.9</td>\n",
       "      <td>56159.9</td>\n",
       "      <td>12.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:03:00</th>\n",
       "      <td>56403.6</td>\n",
       "      <td>56814.0</td>\n",
       "      <td>56168.6</td>\n",
       "      <td>56569.8</td>\n",
       "      <td>5.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:04:00</th>\n",
       "      <td>56612.9</td>\n",
       "      <td>56741.0</td>\n",
       "      <td>56612.9</td>\n",
       "      <td>56612.9</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:05:00</th>\n",
       "      <td>56612.9</td>\n",
       "      <td>57230.6</td>\n",
       "      <td>56386.4</td>\n",
       "      <td>56612.9</td>\n",
       "      <td>18.762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29779 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "Open time (1M)                                                 \n",
       "2024-06-18 03:47:00  66519.3  66519.3  66490.0  66490.0   1.022\n",
       "2024-06-18 03:48:00  66519.3  66519.3  66490.0  66490.5   0.762\n",
       "2024-06-18 03:49:00  66490.6  66519.2  66490.0  66490.0   1.298\n",
       "2024-06-18 03:50:00  66492.0  66500.0  66492.0  66500.0   2.510\n",
       "2024-06-18 03:51:00  66500.0  66500.0  66492.0  66500.0   3.236\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2024-07-08 20:01:00  56612.0  56612.0  56200.0  56309.4   5.851\n",
       "2024-07-08 20:02:00  56256.8  56814.0  56159.9  56159.9  12.976\n",
       "2024-07-08 20:03:00  56403.6  56814.0  56168.6  56569.8   5.523\n",
       "2024-07-08 20:04:00  56612.9  56741.0  56612.9  56612.9   0.247\n",
       "2024-07-08 20:05:00  56612.9  57230.6  56386.4  56612.9  18.762\n",
       "\n",
       "[29779 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTCUSDT_Filtered_data_1M_last_month_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (1M)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:06:00</th>\n",
       "      <td>56839.4</td>\n",
       "      <td>56839.4</td>\n",
       "      <td>55706.9</td>\n",
       "      <td>56713.7</td>\n",
       "      <td>20.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:07:00</th>\n",
       "      <td>56713.7</td>\n",
       "      <td>56741.0</td>\n",
       "      <td>56155.1</td>\n",
       "      <td>56386.4</td>\n",
       "      <td>9.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:08:00</th>\n",
       "      <td>56306.2</td>\n",
       "      <td>56569.8</td>\n",
       "      <td>56244.4</td>\n",
       "      <td>56339.9</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:09:00</th>\n",
       "      <td>56373.9</td>\n",
       "      <td>56839.4</td>\n",
       "      <td>56343.5</td>\n",
       "      <td>56569.8</td>\n",
       "      <td>3.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:10:00</th>\n",
       "      <td>56689.4</td>\n",
       "      <td>56796.1</td>\n",
       "      <td>56386.5</td>\n",
       "      <td>56576.0</td>\n",
       "      <td>2.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:42:00</th>\n",
       "      <td>64354.5</td>\n",
       "      <td>64354.5</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>1.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:43:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:44:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>1.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:45:00</th>\n",
       "      <td>64438.2</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:46:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.0</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.2</td>\n",
       "      <td>1.544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13421 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "Open time (1M)                                                 \n",
       "2024-07-08 20:06:00  56839.4  56839.4  55706.9  56713.7  20.803\n",
       "2024-07-08 20:07:00  56713.7  56741.0  56155.1  56386.4   9.993\n",
       "2024-07-08 20:08:00  56306.2  56569.8  56244.4  56339.9   0.903\n",
       "2024-07-08 20:09:00  56373.9  56839.4  56343.5  56569.8   3.120\n",
       "2024-07-08 20:10:00  56689.4  56796.1  56386.5  56576.0   2.644\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2024-07-18 03:42:00  64354.5  64354.5  64280.1  64280.1   1.119\n",
       "2024-07-18 03:43:00  64280.1  64280.1  64280.1  64280.1   0.000\n",
       "2024-07-18 03:44:00  64280.1  64438.2  64280.1  64280.1   1.505\n",
       "2024-07-18 03:45:00  64438.2  64438.2  64280.1  64438.2   0.053\n",
       "2024-07-18 03:46:00  64280.1  64438.0  64280.1  64280.2   1.544\n",
       "\n",
       "[13421 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTCUSDT_Filtered_data_1M_last_month_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (1M)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:47:00</th>\n",
       "      <td>64280.2</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.2</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "Open time (1M)                                                 \n",
       "2024-07-18 03:47:00  64280.2  64438.2  64280.2  64438.2    1.43"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTCUSDT_Filtered_data_1M_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTCUSDT_Filtered_data_1M = pd.read_csv(full_csv_path, usecols = ['Open time (1M)', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "# BTCUSDT_Filtered_data_1M.set_index('Open time (1M)', inplace = True)\n",
    "\n",
    "# # Convert the index to datetime format\n",
    "# BTCUSDT_Filtered_data_1M.index = pd.to_datetime(BTCUSDT_Filtered_data_1M.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTCUSDT_Filtered_data_1M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Making Of The Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Backbone</th>\n",
       "      <th>Nickname</th>\n",
       "      <th>Coin</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Timeframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBV_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Rayla</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMMA_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Aravos</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>SMMA</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MACD_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>MACD</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STOCHRSI_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Ezran</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>STOCHRSI</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADX_PSAR_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Horsehead</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>ADX_PSAR</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>KALMAN_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-23</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>KALMAN</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TBATS_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-24</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>TBATS</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RNN_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-25</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>RNN</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>TIDE_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-26</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>TIDE</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>XGBOOST_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-27</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name Model Backbone   Nickname     Coin  Strategy  \\\n",
       "0                      OBV_1h             TI      Rayla  BTCUSDT       OBV   \n",
       "1                     SMMA_1h             TI     Aravos  BTCUSDT      SMMA   \n",
       "2                     MACD_1h             TI   Stardust  BTCUSDT      MACD   \n",
       "3                 STOCHRSI_1h             TI      Ezran  BTCUSDT  STOCHRSI   \n",
       "4                 ADX_PSAR_1h             TI  Horsehead  BTCUSDT  ADX_PSAR   \n",
       "..                        ...            ...        ...      ...       ...   \n",
       "69   KALMAN_DARTS_UNTESTED_4h          DARTS       X-23  BTCUSDT    KALMAN   \n",
       "70    TBATS_DARTS_UNTESTED_4h          DARTS       X-24  BTCUSDT     TBATS   \n",
       "71      RNN_DARTS_UNTESTED_4h          DARTS       X-25  BTCUSDT       RNN   \n",
       "72     TIDE_DARTS_UNTESTED_4h          DARTS       X-26  BTCUSDT      TIDE   \n",
       "73  XGBOOST_DARTS_UNTESTED_4h          DARTS       X-27  BTCUSDT   XGBOOST   \n",
       "\n",
       "   Timeframe  \n",
       "0         1h  \n",
       "1         1h  \n",
       "2         1h  \n",
       "3         1h  \n",
       "4         1h  \n",
       "..       ...  \n",
       "69        4h  \n",
       "70        4h  \n",
       "71        4h  \n",
       "72        4h  \n",
       "73        4h  \n",
       "\n",
       "[74 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models_info_df = pd.read_csv(full_csv_path_2, index_col = 0)\n",
    "all_models_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def get_seconds_from_timeframe(timeframe):\n",
    "    \"\"\"\n",
    "    Convert timeframe string (e.g., '1h', '4h') to seconds.\n",
    "    \"\"\"\n",
    "    unit = timeframe[-1]\n",
    "    value = int(timeframe[:-1])\n",
    "    if unit == 'h':\n",
    "        return value * 3600  # Convert hours to seconds\n",
    "    elif unit == 'm':\n",
    "        return value * 60    # Convert minutes to seconds\n",
    "    elif unit == 's':\n",
    "        return value         # Already in seconds\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown timeframe unit: {unit}\")\n",
    "\n",
    "def filter_dataframe_by_time(df, current_time):\n",
    "    # Convert the current time to seconds since midnight\n",
    "    seconds_since_midnight = current_time.hour * 3600 + current_time.minute * 60 - 600 # Subtracting 10 minutes\n",
    "\n",
    "    # Filter the dataframe based on whether the current time is divisible by the timeframe in seconds\n",
    "    filtered_df = df[df['Timeframe'].apply(lambda tf: seconds_since_midnight % get_seconds_from_timeframe(tf) == 0)]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Get the current time\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    # Filter the DataFrame based on the current time\n",
    "    filtered_df = filter_dataframe_by_time(copy.deepcopy(all_models_info_df), current_time)\n",
    "    if filtered_df.empty:\n",
    "        print('No models fit in this timeframe')\n",
    "    else:\n",
    "        print(filtered_df)\n",
    "\n",
    "    print('Now waiting 60 seconds to check again!')\n",
    "    # Sleep for a minute before checking again\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 8, 13, 0, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = datetime(2024, 8, 13, 0, 10, 0, 0)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Backbone</th>\n",
       "      <th>Nickname</th>\n",
       "      <th>Coin</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Timeframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBV_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Rayla</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMMA_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Aravos</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>SMMA</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MACD_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>MACD</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STOCHRSI_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Ezran</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>STOCHRSI</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADX_PSAR_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Horsehead</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>ADX_PSAR</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>KALMAN_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-23</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>KALMAN</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TBATS_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-24</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>TBATS</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RNN_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-25</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>RNN</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>TIDE_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-26</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>TIDE</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>XGBOOST_DARTS_UNTESTED_4h</td>\n",
       "      <td>DARTS</td>\n",
       "      <td>X-27</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name Model Backbone   Nickname     Coin  Strategy  \\\n",
       "0                      OBV_1h             TI      Rayla  BTCUSDT       OBV   \n",
       "1                     SMMA_1h             TI     Aravos  BTCUSDT      SMMA   \n",
       "2                     MACD_1h             TI   Stardust  BTCUSDT      MACD   \n",
       "3                 STOCHRSI_1h             TI      Ezran  BTCUSDT  STOCHRSI   \n",
       "4                 ADX_PSAR_1h             TI  Horsehead  BTCUSDT  ADX_PSAR   \n",
       "..                        ...            ...        ...      ...       ...   \n",
       "69   KALMAN_DARTS_UNTESTED_4h          DARTS       X-23  BTCUSDT    KALMAN   \n",
       "70    TBATS_DARTS_UNTESTED_4h          DARTS       X-24  BTCUSDT     TBATS   \n",
       "71      RNN_DARTS_UNTESTED_4h          DARTS       X-25  BTCUSDT       RNN   \n",
       "72     TIDE_DARTS_UNTESTED_4h          DARTS       X-26  BTCUSDT      TIDE   \n",
       "73  XGBOOST_DARTS_UNTESTED_4h          DARTS       X-27  BTCUSDT   XGBOOST   \n",
       "\n",
       "   Timeframe  \n",
       "0         1h  \n",
       "1         1h  \n",
       "2         1h  \n",
       "3         1h  \n",
       "4         1h  \n",
       "..       ...  \n",
       "69        4h  \n",
       "70        4h  \n",
       "71        4h  \n",
       "72        4h  \n",
       "73        4h  \n",
       "\n",
       "[74 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame based on the current time\n",
    "filtered_df = filter_dataframe_by_time(copy.deepcopy(all_models_info_df), temp)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Backbone</th>\n",
       "      <th>Nickname</th>\n",
       "      <th>Coin</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Timeframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBV_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Rayla</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMMA_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Aravos</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>SMMA</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MACD_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>MACD</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STOCHRSI_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Ezran</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>STOCHRSI</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADX_PSAR_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Horsehead</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>ADX_PSAR</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EMA_1h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Cygnus</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>EMA</td>\n",
       "      <td>1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OBV_4h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Anak Arao</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SMMA_4h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Elarion</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>SMMA</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MACD_4h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Ziard</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>MACD</td>\n",
       "      <td>4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OBV_6h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Corvus</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>6h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MACD_6h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Kpp'Ar</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>MACD</td>\n",
       "      <td>6h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SMMA_6h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>SMMA</td>\n",
       "      <td>6h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>OBV_8h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Viren</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>8h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMMA_8h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Finnegrin</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>SMMA</td>\n",
       "      <td>8h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>OBV_12h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Kruha</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>12h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SMMA_12h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Moondrop</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>SMMA</td>\n",
       "      <td>12h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>OBV_16h</td>\n",
       "      <td>TI</td>\n",
       "      <td>The Being</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>16h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>OBV_24h</td>\n",
       "      <td>TI</td>\n",
       "      <td>Aegis</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>OBV</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Name Model Backbone   Nickname     Coin  Strategy Timeframe\n",
       "0        OBV_1h             TI      Rayla  BTCUSDT       OBV        1h\n",
       "1       SMMA_1h             TI     Aravos  BTCUSDT      SMMA        1h\n",
       "2       MACD_1h             TI   Stardust  BTCUSDT      MACD        1h\n",
       "3   STOCHRSI_1h             TI      Ezran  BTCUSDT  STOCHRSI        1h\n",
       "4   ADX_PSAR_1h             TI  Horsehead  BTCUSDT  ADX_PSAR        1h\n",
       "5        EMA_1h             TI     Cygnus  BTCUSDT       EMA        1h\n",
       "14       OBV_4h             TI  Anak Arao  BTCUSDT       OBV        4h\n",
       "15      SMMA_4h             TI    Elarion  BTCUSDT      SMMA        4h\n",
       "16      MACD_4h             TI      Ziard  BTCUSDT      MACD        4h\n",
       "39       OBV_6h             TI     Corvus  BTCUSDT       OBV        6h\n",
       "40      MACD_6h             TI     Kpp'Ar  BTCUSDT      MACD        6h\n",
       "41      SMMA_6h             TI      Lucia  BTCUSDT      SMMA        6h\n",
       "47       OBV_8h             TI      Viren  BTCUSDT       OBV        8h\n",
       "48      SMMA_8h             TI  Finnegrin  BTCUSDT      SMMA        8h\n",
       "53      OBV_12h             TI      Kruha  BTCUSDT       OBV       12h\n",
       "54     SMMA_12h             TI   Moondrop  BTCUSDT      SMMA       12h\n",
       "60      OBV_16h             TI  The Being  BTCUSDT       OBV       16h\n",
       "64      OBV_24h             TI      Aegis  BTCUSDT       OBV       24h"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_ti = filtered_df[filtered_df['Model Backbone'] == 'TI']\n",
    "filtered_df_ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals_ti(df, strategy):\n",
    "    match strategy:\n",
    "        case \"MACD\":\n",
    "            print(f\"\\n{colors.BLUE}MACD Strategy detected.{colors.RESET}\")\n",
    "            \n",
    "            # Calculate MACD for the 4-Hour data\n",
    "            signal_df = calculate_macd(copy.deepcopy(df))\n",
    "            \n",
    "            # Generate trading signals based on MACD\n",
    "            signal_df = generate_macd_signals(signal_df)\n",
    "        \n",
    "        case \"ADX_PSAR\":\n",
    "            print(f\"\\n{colors.BLUE}ADX PSAR Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Calculate ADX and Parabolic SAR\n",
    "            signal_df = calculate_adx(copy.deepcopy(df), window = 14)\n",
    "            signal_df = calculate_parabolic_sar(signal_df)\n",
    "            \n",
    "            # Generate trading signals\n",
    "            signal_df = generate_adx_parabolic_sar_signals(signal_df)\n",
    "        \n",
    "        case \"RSI\":\n",
    "            print(f\"\\n{colors.BLUE}RSI Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Calculate RSI for the 1-Hour data\n",
    "            signal_df = calculate_rsi(copy.deepcopy(df))\n",
    "            \n",
    "            # Generate trading signals based on RSI\n",
    "            signal_df = generate_rsi_signals(signal_df)\n",
    "        \n",
    "        case \"STOCHRSI\":\n",
    "            print(f\"\\n{colors.BLUE}STOCHASTIC RSI Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Calculate RSI for the 1-Hour data\n",
    "            signal_df = calculate_stochrsi(copy.deepcopy(df), fillna = True)\n",
    "            \n",
    "            # Generate trading signals based on RSI\n",
    "            signal_df = generate_stochrsi_signals(signal_df)\n",
    "        \n",
    "        case \"OBV\":\n",
    "            print(f\"\\n{colors.BLUE}On-Balance Volume Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Calculate The On-Balance Volume (OBV)\n",
    "            signal_df = calculate_obv(copy.deepcopy(df), fillna = True)\n",
    "            \n",
    "            # Generate Signals Using OBV\n",
    "            signal_df = generate_obv_signals(signal_df)\n",
    "\n",
    "        case \"SMA\":\n",
    "            print(f\"\\n{colors.BLUE}SMA Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Assuming `df` is your DataFrame containing 'Close' prices\n",
    "            signal_df = generate_sma_signals(copy.deepcopy(df), short_window=50, long_window=200)\n",
    "        \n",
    "        case \"EMA\":\n",
    "            print(f\"\\n{colors.BLUE}EMA Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Generate trading signals using ema\n",
    "            signal_df = generate_triple_ema_signals(copy.deepcopy(df), short_window = 5, medium_window = 21, long_window = 50)\n",
    "        \n",
    "        case \"SMMA\":\n",
    "            print(f\"\\n{colors.BLUE}SMMA Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Generate trading signals using smma \n",
    "            signal_df = generate_smma_signals(copy.deepcopy(df), window=14)\n",
    "\n",
    "        case \"VWMA\":\n",
    "            print(f\"\\n{colors.BLUE}VWMA Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Generate trading signals using vwma\n",
    "            signal_df = generate_vwma_signals(copy.deepcopy(df), short_window=10, long_window=50)\n",
    "        \n",
    "        case \"AO\":\n",
    "            print(f\"\\n{colors.BLUE}AWESOME OSCILLATOR Strategy detected.{colors.RESET}\")\n",
    "\n",
    "            # Calculate The Awesome Oscillator (AO)\n",
    "            signal_df = calculate_AO(copy.deepcopy(df), fillna = True)\n",
    "            \n",
    "            # Generate Signals Using OBV\n",
    "            signal_df = generate_AO_signals(signal_df)\n",
    "            \n",
    "        case _:\n",
    "            raise AttributeError(f'\\n{colors.WARNING}An Unknown Strategy Name Was Found!{colors.RESET}')\n",
    "\n",
    "    # Reserve the last signal and prediction time (for the future prediction)\n",
    "    last_signal = signal_df['Signal'].iloc[-1]\n",
    "    last_signal_time = signal_df.index[-1]\n",
    "\n",
    "    # Shift all the signal data points one step ahead (down) to mimic future prediction of past data\n",
    "    signal_df['Signal'] = signal_df['Signal'].shift(1).fillna(0)\n",
    "    signal_df = signal_df[1:].copy()\n",
    "\n",
    "    return signal_df, last_signal, last_signal_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals_ml(df, strategy, model_path):\n",
    "\n",
    "    # Define the function to generate signals\n",
    "    def generate_signal(row):\n",
    "        if row['Close'] > row['Predicted']:\n",
    "            return -1\n",
    "        elif row['Close'] < row['Predicted']:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def load_model(model_path):\n",
    "        \"\"\"\n",
    "        Load a model from disk.\n",
    "        \n",
    "        Parameters:\n",
    "        filename (str): The path from which to load the model.\n",
    "        \n",
    "        Returns:\n",
    "        model (sklearn.base.BaseEstimator): The loaded model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model = joblib.load(model_path)\n",
    "            print(f\"{colors.GREEN}Model loaded from {model_path}{colors.RESET}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"{colors.WARNING}Failed to load model. Error: {e}{colors.RESET}\")\n",
    "            return None\n",
    "\n",
    "    print(f\"\\n{colors.BLUE}{strategy} Strategy detected.{colors.RESET}\")\n",
    "\n",
    "    # # Temporary\n",
    "    # if 'OPTUNA' in strategy:\n",
    "    #     print(f'{colors.WARNING}OPTUNA Models are not implemented yet. Skipping...{colors.RESET}')\n",
    "    #     return None, None, None\n",
    "\n",
    "    # Load the desired model\n",
    "    model = load_model(model_path)\n",
    "    if model is None:\n",
    "        print(f'{colors.WARNING}Unexpcted behaviour. Model loaded as None Type.{colors.RESET}')\n",
    "        return None, None, None\n",
    "\n",
    "    # Get the close price predictions from the model\n",
    "    close_pred = model.predict(df)\n",
    "\n",
    "    # Add the predictions to the Dataframe\n",
    "    df['Predicted'] = close_pred\n",
    "\n",
    "    # Apply the function to create the 'Signal' column\n",
    "    # and also extract the last predicted signal and\n",
    "    # the last predicted signal's time for further \n",
    "    # use in the simulation code.\n",
    "    df.loc[:, 'Signal'] = df.apply(generate_signal, axis=1)\n",
    "    last_signal = df['Signal'].iloc[-1]\n",
    "    last_signal_time = df.index[-1]\n",
    "\n",
    "    # Shift the 'Signal' column\n",
    "    df.loc[:, 'Signal'] = df['Signal'].shift(1).fillna(0)\n",
    "    \n",
    "    # Drop the first row because it has a NaN value in 'Signal Actual'\n",
    "    signal_df = df[1:].copy()\n",
    "\n",
    "    return signal_df, last_signal, last_signal_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "class colors:\n",
    "    BLUE = '\\033[94m'\n",
    "    YELLOW = '\\033[33m'\n",
    "    GREEN = '\\033[92m'\n",
    "    WARNING = '\\033[31m'\n",
    "    RESET = '\\033[0m'\n",
    "\n",
    "def simulation(df, df_info):\n",
    "    # Store all timeframe dataframes required in a dictionary\n",
    "    # Assuming df contains your model information\n",
    "    timeframes = df_info['Timeframe'].unique()  # Extract unique timeframes\n",
    "    \n",
    "    # Dictionary to store resampled dataframes\n",
    "    timeframe_dfs = {}\n",
    "    \n",
    "    # Iterate over each unique timeframe and resample the data accordingly\n",
    "    for timeframe in timeframes:\n",
    "        # Convert the original DataFrame to the specific timeframe using your conversion function\n",
    "        resampled_df = convert_1m_to_any_timeframe(copy.deepcopy(df), timeframe)\n",
    "        \n",
    "        # Store the resampled dataframe in the dictionary with the timeframe as the key\n",
    "        timeframe_dfs[timeframe] = resampled_df\n",
    "\n",
    "    # Settig Up The Directory From The Directory Hierarchy\n",
    "    # Get the notebook's current directory\n",
    "    notebook_dir = os.getcwd()\n",
    "    \n",
    "    # Go up one level to the parent directory\n",
    "    parent_dir = os.path.abspath(os.path.join(notebook_dir, os.pardir))\n",
    "    \n",
    "    # Go to the main data directory andgo to the models directory\n",
    "    data_dir = os.path.join(parent_dir, \"data\")\n",
    "    model_dir = os.path.join(data_dir, 'models')\n",
    "\n",
    "    # Go the the ledger directory in the 'model' directory\n",
    "    ledger_dir = os.path.join(model_dir, 'ledger')\n",
    "\n",
    "    # Go to the current status directory in the 'model' directory\n",
    "    current_status_dir = os.path.join(model_dir, 'current status')\n",
    "\n",
    "    # Go to the statistics directory in the 'model' directory\n",
    "    statistics_dir = os.path.join(model_dir, 'statistics')\n",
    "\n",
    "    # Go to the pickle files directory in the 'model' directory\n",
    "    pickle_files_dir = os.path.join(model_dir, 'pickle files')\n",
    "\n",
    "    # Go to the metadata directory in the 'model' directory\n",
    "    metadata_dir = os.path.join(model_dir, 'metadata')\n",
    "    metadata_file = os.path.join(metadata_dir, 'metadata.csv')\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(ledger_dir, exist_ok=True)\n",
    "    os.makedirs(current_status_dir, exist_ok=True)\n",
    "    os.makedirs(statistics_dir, exist_ok=True)\n",
    "    os.makedirs(metadata_dir, exist_ok=True)\n",
    "    os.makedirs(pickle_files_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through each row of the DataFrame\n",
    "    for _, row in df_info.iterrows():\n",
    "        strategy = row['Strategy']\n",
    "        timeframe = row['Timeframe']\n",
    "        nickname = row['Nickname']\n",
    "        backbone = row['Model Backbone']\n",
    "        coin = row['Coin']\n",
    "        \n",
    "        # Define the path to all the file\n",
    "        ledger_file = os.path.join(ledger_dir, f'{nickname}.csv')\n",
    "        status_file = os.path.join(current_status_dir, f'{nickname}_status.csv')\n",
    "        statistics_file = os.path.join(statistics_dir, f'{nickname}_stats.csv')\n",
    "        model_pickle_file = os.path.join(pickle_files_dir, f'{nickname}.pkl')\n",
    "        \n",
    "        # Select the correct timeframe DataFrame from the dictionary\n",
    "        required_df = timeframe_dfs[timeframe]\n",
    "        \n",
    "        # Generate signals based on the strategy\n",
    "        if backbone == 'TI':\n",
    "            signals_df, last_signal, last_signal_time = generate_signals_ti(copy.deepcopy(required_df), strategy)\n",
    "        elif backbone == 'ML':\n",
    "            signals_df, last_signal, last_signal_time = generate_signals_ml(copy.deepcopy(required_df), strategy, model_pickle_file)\n",
    "        elif backbone == 'DL':\n",
    "            print(f'{colors.WARNING}Deep Learning Models are not implemented yet. Skipping...{colors.RESET}')\n",
    "            continue\n",
    "        elif backbone == 'DARTS':\n",
    "            print(f'{colors.WARNING}DART Models are not implemented yet. Skipping...{colors.RESET}')\n",
    "            continue\n",
    "\n",
    "        # Check if signals_df is None. (Meaning model loaded as None Type: Unexpected Behaviour)\n",
    "        if signals_df is None:\n",
    "            continue\n",
    "        \n",
    "        # Check if signals_df is not empty before proceeding\n",
    "        if signals_df.empty:\n",
    "            print(f\"{colors.WARNING}No signals generated for {nickname}. Skipping...{colors.RESET}\")\n",
    "            continue\n",
    "\n",
    "        # Saving part of signal dataframe for frequency inferring in backtesting function\n",
    "        df_for_freq_inferring = signals_df[-10:].copy()\n",
    "        \n",
    "        # Generate the new ledger using the backtesting function\n",
    "        if os.path.exists(ledger_file):\n",
    "            # Reading the exisitng ledger\n",
    "            existing_ledger = pd.read_csv(ledger_file)\n",
    "            existing_ledger.set_index(existing_ledger.columns[0], inplace = True)\n",
    "            existing_ledger.index = pd.to_datetime(existing_ledger.index)\n",
    "\n",
    "            # Extracting the balance till the last trade\n",
    "            last_balance_at_that_time = existing_ledger['Balance'].iloc[-1]\n",
    "\n",
    "            # Getting only the required signals\n",
    "            signals_df = signals_df[signals_df.index >= existing_ledger.index[-1]]\n",
    "\n",
    "            # Generate the new backtest ledger\n",
    "            new_ledger = generate_backtest_df(signals_df, df[str(signals_df.index[0]): str(signals_df.index[-1])].copy(), df_for_freq_inferring, last_balance_at_that_time)\n",
    "\n",
    "            # If ledger returned is empty, dont concatenate, else concatenate\n",
    "            if new_ledger.empty:\n",
    "                for_stats = existing_ledger.copy()\n",
    "            else:\n",
    "                for_stats = pd.concat([existing_ledger, new_ledger])\n",
    "                for_stats = for_stats.sort_index()\n",
    "        else:\n",
    "            new_ledger = generate_backtest_df(signals_df, df[str(signals_df.index[0]): str(signals_df.index[-1])].copy(), df_for_freq_inferring)\n",
    "            for_stats = new_ledger.copy()\n",
    "\n",
    "        # If no signal change is detected, (no trade has begun)\n",
    "        if for_stats.empty:\n",
    "            print(f\"{colors.WARNING}Empty ledger created for {nickname} - no trades held. Skipping...{colors.RESET}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate the stats df\n",
    "        new_ledger_with_all_pnl = calculate_pnl_sum_all(for_stats.reset_index())\n",
    "        _, stats_df = calculate_all_statistics(new_ledger_with_all_pnl)\n",
    "\n",
    "        # Retrieve the cumulative pnl from stats_df to save to metadata csv\n",
    "        cumulative_pnl = stats_df['Total PnL (%)'].iloc[-1]\n",
    "\n",
    "        # SAVING TO CSVS / DATABASES\n",
    "        # Appending or saving to the ledger file\n",
    "        try:\n",
    "            # Determine if the file already exists\n",
    "            if os.path.exists(ledger_file):\n",
    "\n",
    "                # Check if ledger is empty, then data is already up to date\n",
    "                if new_ledger.empty:\n",
    "                    print(f'{colors.YELLOW}Ledger data already up to date!{colors.RESET}')\n",
    "                else:\n",
    "                    # Append the newly fetched data to the existing CSV without header\n",
    "                    new_ledger.to_csv(ledger_file, mode='a', header=False, index=True)\n",
    "                    print(f\"{colors.GREEN}Ledger appended to {colors.BLUE}{ledger_file}{colors.RESET}\")\n",
    "            else:\n",
    "                # Write the new data with header since file does not exist\n",
    "                new_ledger.to_csv(ledger_file, mode='w', header=True, index=True)\n",
    "                print(f\"{colors.GREEN}Ledger created and ledger saved to {colors.BLUE}{ledger_file}{colors.RESET}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{colors.WARNING}Failed to save / append ledger to {colors.BLUE}{ledger_file}. Error: {e}{colors.RESET}\")\n",
    "\n",
    "        # Saving to the status file\n",
    "        try:\n",
    "            # Get the current prediction time\n",
    "            current_prediction_time = last_signal_time + pd.Timedelta(timeframe)\n",
    "            \n",
    "            # Calculate the next prediction time by adding the timeframe as a Timedelta\n",
    "            next_prediction_time = current_prediction_time + pd.Timedelta(timeframe)\n",
    "            \n",
    "            # Convert both times to strings\n",
    "            current_prediction_time = str(current_prediction_time)\n",
    "            next_prediction_time = str(next_prediction_time)\n",
    "\n",
    "            # Get the current prediction\n",
    "            current_prediction = last_signal\n",
    "\n",
    "            if new_ledger.empty:\n",
    "                current_balance = existing_ledger['Balance'].iloc[-1]\n",
    "            else:\n",
    "                current_balance = new_ledger['Balance'].iloc[-1]\n",
    "\n",
    "            pd.DataFrame({\n",
    "                'Model Name': [nickname],\n",
    "                'Timeframe' : [timeframe],\n",
    "                'Current Prediction Time': [current_prediction_time],\n",
    "                'Current Prediction': [current_prediction],\n",
    "                'Next Prediction Time': [next_prediction_time],\n",
    "            }).to_csv(status_file, mode='w', header=True, index=True)\n",
    "\n",
    "            print(f\"{colors.GREEN}Status saved to {colors.BLUE}{status_file}{colors.RESET}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{colors.WARNING}Failed to save status to {colors.BLUE}{status_file}. Error: {e}{colors.RESET}\")\n",
    "\n",
    "        # Saving to the statistics file\n",
    "        try:\n",
    "            # Determine if the file already exists\n",
    "            if os.path.exists(statistics_file):\n",
    "                # If it exists, read it into a DataFrame\n",
    "                existing_stats = pd.read_csv(statistics_file)\n",
    "                existing_stats.set_index(existing_stats.columns[0], inplace = True)\n",
    "                existing_stats.index = pd.to_datetime(existing_stats.index, format='mixed')\n",
    "                \n",
    "                # Find the index where the new ledger starts\n",
    "                last_stats_index = existing_stats.index[-1]\n",
    "\n",
    "                # Get only those values that are \n",
    "                stats_df = stats_df[stats_df.index > pd.to_datetime(last_stats_index)]\n",
    "\n",
    "                if stats_df.empty:\n",
    "                    print(f'{colors.YELLOW}Stats data already up to date!{colors.RESET}{colors.GREEN}')\n",
    "                else:\n",
    "                    # Append the newly fetched data to the existing CSV without header\n",
    "                    stats_df.to_csv(statistics_file, mode='a', header=False, index=True)\n",
    "                    print(f\"{colors.GREEN}Stats appended to {colors.BLUE}{statistics_file}{colors.RESET}\")\n",
    "            else:\n",
    "                # Write the new data with header since file does not exist\n",
    "                stats_df.to_csv(statistics_file, mode='w', header=True, index=True)\n",
    "                print(f\"{colors.GREEN}Stats created and stats saved to {colors.BLUE}{statistics_file}{colors.RESET}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{colors.WARNING}Failed to save / append stats to {colors.BLUE}{statistics_file}. Error: {e}{colors.RESET}\")\n",
    "\n",
    "        # Saving to the metadata file\n",
    "        try:\n",
    "            # Make a list of the new values\n",
    "            new_values = [nickname, backbone, coin, timeframe, current_prediction_time, current_prediction, next_prediction_time, cumulative_pnl]\n",
    "            \n",
    "            # Determine if the file already exists\n",
    "            if os.path.exists(metadata_file):\n",
    "                # If it exists, read it into a DataFrame\n",
    "                existing_metadata = pd.read_csv(metadata_file)\n",
    "        \n",
    "                # Check if the model is present and update the row\n",
    "                if nickname in existing_metadata['Model Name'].values:\n",
    "                    # Get the current row\n",
    "                    current_row = existing_metadata.loc[existing_metadata['Model Name'] == nickname]\n",
    "                    \n",
    "                    # Check if any of the values are different\n",
    "                    if current_row.iloc[0].to_list() != new_values:\n",
    "                        # Update the row with the new values\n",
    "                        existing_metadata.loc[existing_metadata['Model Name'] == nickname, :] = new_values\n",
    "                        existing_metadata.to_csv(metadata_file, mode='w', header=True, index=False)\n",
    "                        print(f\"{colors.GREEN}Metadata for {nickname} updated and saved to {colors.BLUE}{metadata_file}{colors.RESET}\")\n",
    "                    else:\n",
    "                        print(f\"{colors.YELLOW}Metadata for {nickname} is already up to date!{colors.RESET}\")\n",
    "                else:\n",
    "                    # Add a new row to the DataFrame\n",
    "                    new_row = pd.DataFrame(\n",
    "                        [new_values],\n",
    "                        columns = [\n",
    "                            'Model Name',\n",
    "                            'Backbone',\n",
    "                            'Coin',\n",
    "                            'Timeframe',\n",
    "                            'Current Prediction Time',\n",
    "                            'Current Prediction',\n",
    "                            'Next Prediction Time',\n",
    "                            'Total PNL'\n",
    "                        ]\n",
    "                    )\n",
    "                    \n",
    "                    # Add the new row to the existing DataFrame\n",
    "                    existing_metadata = pd.concat([existing_metadata, new_row], axis=0, ignore_index=True)\n",
    "        \n",
    "                    # Overwrite to the new CSV\n",
    "                    existing_metadata.to_csv(metadata_file, mode='w', header=True, index=False)\n",
    "                    print(f\"{colors.GREEN}Metadata for {nickname} added / appended to {colors.BLUE}{metadata_file}{colors.RESET}\")\n",
    "            else:\n",
    "                # Write the new data with header since the file does not exist\n",
    "                pd.DataFrame({\n",
    "                    'Model Name': [nickname],\n",
    "                    'Backbone' : [backbone],\n",
    "                    'Coin': [coin],\n",
    "                    'Timeframe': [timeframe],\n",
    "                    'Current Prediction Time': [current_prediction_time],\n",
    "                    'Current Prediction': [current_prediction],\n",
    "                    'Next Prediction Time': [next_prediction_time],\n",
    "                    'Total PNL': [cumulative_pnl]\n",
    "                }).to_csv(metadata_file, mode='w', header=True, index=False)\n",
    "                \n",
    "                print(f\"{colors.GREEN}Metadata created and metadata for {nickname} saved to {colors.BLUE}{metadata_file}{colors.RESET}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{colors.WARNING}Failed to save / add / append metadata to {colors.BLUE}{metadata_file}. Error: {e}{colors.RESET}\")\n",
    "\n",
    "        # Adding a new line after every model prediction\n",
    "        print()\n",
    "\n",
    "    print(f'\\n{colors.GREEN}Simulation Completed Succesfully!{colors.RESET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94mOn-Balance Volume Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Rayla_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Rayla is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSMMA Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Aravos_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Aravos is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mMACD Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Stardust_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Stardust is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSTOCHASTIC RSI Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Ezran_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Ezran is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mADX PSAR Strategy detected.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\anaconda3\\envs\\neurog\\Lib\\site-packages\\ta\\trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Horsehead_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Horsehead is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mEMA Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Cygnus_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Cygnus is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Azymondius.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Azymondius_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Azymondius is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mVR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Sol Regem.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Sol Regem_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Sol Regem is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mMLPR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Avizandum.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Avizandum_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Avizandum is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mETR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Elder.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Elder_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Elder is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mRFR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Domina Profundus.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Domina Profundus_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Domina Profundus is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Zubeia.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Zubeia_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Zubeia is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mGBR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Rex Igneus.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Rex Igneus_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Rex Igneus is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mABR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Xadia.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Xadia_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Xadia is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mOn-Balance Volume Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Anak Arao_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Anak Arao is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSMMA Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Elarion_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Elarion is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mMACD Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Ziard_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Ziard is already up to date!\u001b[0m\n",
      "\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\n",
      "\u001b[94mSGDR_OPTUNA_2 Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Drakewood.pkl\u001b[0m\n",
      "\u001b[31mEmpty ledger created for Drakewood - no trades held. Skipping...\u001b[0m\n",
      "\n",
      "\u001b[94mGBR_OPTUNA Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Umber Tor.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Umber Tor_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Umber Tor is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mXGBOOST_OPTUNA Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Ibis.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Ibis_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Ibis is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLIGHTGBM_OPTUNA Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Runaan.pkl\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8236017197784742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8236017197784742\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4839213779842821e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4839213779842821e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.466963535388834e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.466963535388834e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7973306870798275, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7973306870798275\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "\u001b[31mEmpty ledger created for Runaan - no trades held. Skipping...\u001b[0m\n",
      "\n",
      "\u001b[94mSGDR_OPTUNA_1 Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Banther.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Banther_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Banther is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mCATBOOST_OPTUNA Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Bait.pkl\u001b[0m\n",
      "\u001b[31mEmpty ledger created for Bait - no trades held. Skipping...\u001b[0m\n",
      "\n",
      "\u001b[94mLR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Mukho.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Mukho_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Mukho is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSGDR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Soulfang Serpant.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Soulfang Serpant_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Soulfang Serpant is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mETR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Sun Seed.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Sun Seed_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Sun Seed is already up to date!\u001b[0m\n",
      "\n",
      "\u001b[31mDeep Learning Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDeep Learning Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDeep Learning Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDeep Learning Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDeep Learning Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDeep Learning Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDeep Learning Models are not implemented yet. Skipping...\u001b[0m\n",
      "\n",
      "\u001b[94mOn-Balance Volume Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Corvus_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Corvus is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mMACD Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Kpp'Ar_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Kpp'Ar is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSMMA Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Lucia_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Lucia is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSGDR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Sarai.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Sarai_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Sarai is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Amon.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Amon_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Amon is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mVR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Villads.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Villads_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Villads is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mETR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Dorian.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Dorian_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Dorian is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mMLPR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Dhurwin Mulyall.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Dhurwin Mulyall_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Dhurwin Mulyall is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mOn-Balance Volume Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Viren_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Viren is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSMMA Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Finnegrin_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Finnegrin is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Osato.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Osato_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Osato is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSGDR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Berto.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Berto_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Berto is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mMLPR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Embertail.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Embertail_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Embertail is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mVR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Esmeray.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Esmeray_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Esmeray is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mOn-Balance Volume Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Kruha_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Kruha is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSMMA Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Moondrop_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Moondrop is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSGDR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Quasar.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Quasar_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Quasar is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mETR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Corona Heavens.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Corona Heavens_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Corona Heavens is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mRFR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Phoe Phoe.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Phoe Phoe_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Phoe Phoe is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Stella.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Stella_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Stella is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Terbium.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Terbium_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Terbium is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mOn-Balance Volume Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\The Being_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for The Being is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Groot.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Groot_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Groot is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSGDR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Leola.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Leola_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Leola is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mMLPR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Ahling.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Ahling_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Ahling is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mOn-Balance Volume Strategy detected.\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Aegis_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Aegis is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mLR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Katara.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Katara_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Katara is already up to date!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[94mSGDR Strategy detected.\u001b[0m\n",
      "\u001b[92mModel loaded from C:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\pickle files\\Miyana.pkl\u001b[0m\n",
      "\u001b[92mAll stats calculated!\u001b[0m\n",
      "\u001b[33mLedger data already up to date!\u001b[0m\n",
      "\u001b[92mStatus saved to \u001b[94mC:\\Users\\Ali\\Desktop\\Neurog Internship\\data\\models\\current status\\Miyana_status.csv\u001b[0m\n",
      "\u001b[33mStats data already up to date!\u001b[0m\u001b[92m\n",
      "\u001b[33mMetadata for Miyana is already up to date!\u001b[0m\n",
      "\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\u001b[31mDART Models are not implemented yet. Skipping...\u001b[0m\n",
      "\n",
      "\u001b[92mSimulation Completed Succesfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "simulation(copy.deepcopy(BTCUSDT_Filtered_data_1M_last_month), filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (1M)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:06:00</th>\n",
       "      <td>56839.4</td>\n",
       "      <td>56839.4</td>\n",
       "      <td>55706.9</td>\n",
       "      <td>56713.7</td>\n",
       "      <td>20.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:07:00</th>\n",
       "      <td>56713.7</td>\n",
       "      <td>56741.0</td>\n",
       "      <td>56155.1</td>\n",
       "      <td>56386.4</td>\n",
       "      <td>9.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:08:00</th>\n",
       "      <td>56306.2</td>\n",
       "      <td>56569.8</td>\n",
       "      <td>56244.4</td>\n",
       "      <td>56339.9</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:09:00</th>\n",
       "      <td>56373.9</td>\n",
       "      <td>56839.4</td>\n",
       "      <td>56343.5</td>\n",
       "      <td>56569.8</td>\n",
       "      <td>3.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-08 20:10:00</th>\n",
       "      <td>56689.4</td>\n",
       "      <td>56796.1</td>\n",
       "      <td>56386.5</td>\n",
       "      <td>56576.0</td>\n",
       "      <td>2.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:42:00</th>\n",
       "      <td>64354.5</td>\n",
       "      <td>64354.5</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>1.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:43:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:44:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>1.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:45:00</th>\n",
       "      <td>64438.2</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.2</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 03:46:00</th>\n",
       "      <td>64280.1</td>\n",
       "      <td>64438.0</td>\n",
       "      <td>64280.1</td>\n",
       "      <td>64280.2</td>\n",
       "      <td>1.544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13421 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close  Volume\n",
       "Open time (1M)                                                 \n",
       "2024-07-08 20:06:00  56839.4  56839.4  55706.9  56713.7  20.803\n",
       "2024-07-08 20:07:00  56713.7  56741.0  56155.1  56386.4   9.993\n",
       "2024-07-08 20:08:00  56306.2  56569.8  56244.4  56339.9   0.903\n",
       "2024-07-08 20:09:00  56373.9  56839.4  56343.5  56569.8   3.120\n",
       "2024-07-08 20:10:00  56689.4  56796.1  56386.5  56576.0   2.644\n",
       "...                      ...      ...      ...      ...     ...\n",
       "2024-07-18 03:42:00  64354.5  64354.5  64280.1  64280.1   1.119\n",
       "2024-07-18 03:43:00  64280.1  64280.1  64280.1  64280.1   0.000\n",
       "2024-07-18 03:44:00  64280.1  64438.2  64280.1  64280.1   1.505\n",
       "2024-07-18 03:45:00  64438.2  64438.2  64280.1  64438.2   0.053\n",
       "2024-07-18 03:46:00  64280.1  64438.0  64280.1  64280.2   1.544\n",
       "\n",
       "[13421 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTCUSDT_Filtered_data_1M_last_month_2nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Testing The Stats Calculation Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making The temporary dataframe with obv signals and backtesting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_1m = pd.read_csv(full_csv_path_1, usecols = ['Open time (1M)', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "df_temp_1m.set_index('Open time (1M)', inplace = True)\n",
    "\n",
    "# Convert the index to datetime format\n",
    "df_temp_1m.index = pd.to_datetime(df_temp_1m.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_4h = convert_1m_to_any_timeframe(copy.deepcopy(df_temp_1m), '4h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (1M)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>7169.71</td>\n",
       "      <td>7169.71</td>\n",
       "      <td>7165.44</td>\n",
       "      <td>7167.83</td>\n",
       "      <td>3509.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:00</th>\n",
       "      <td>7167.83</td>\n",
       "      <td>7168.28</td>\n",
       "      <td>7158.66</td>\n",
       "      <td>7159.95</td>\n",
       "      <td>3821.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:02:00</th>\n",
       "      <td>7161.03</td>\n",
       "      <td>7165.40</td>\n",
       "      <td>7161.03</td>\n",
       "      <td>7162.46</td>\n",
       "      <td>3041.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:03:00</th>\n",
       "      <td>7161.74</td>\n",
       "      <td>7164.27</td>\n",
       "      <td>7160.30</td>\n",
       "      <td>7161.03</td>\n",
       "      <td>3682.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:04:00</th>\n",
       "      <td>7161.03</td>\n",
       "      <td>7164.25</td>\n",
       "      <td>7160.15</td>\n",
       "      <td>7160.15</td>\n",
       "      <td>2936.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 23:56:00</th>\n",
       "      <td>64637.90</td>\n",
       "      <td>64742.90</td>\n",
       "      <td>64242.90</td>\n",
       "      <td>64443.60</td>\n",
       "      <td>6.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 23:57:00</th>\n",
       "      <td>64443.60</td>\n",
       "      <td>64742.90</td>\n",
       "      <td>64242.90</td>\n",
       "      <td>64700.00</td>\n",
       "      <td>2.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 23:58:00</th>\n",
       "      <td>64700.00</td>\n",
       "      <td>64700.00</td>\n",
       "      <td>64603.20</td>\n",
       "      <td>64603.20</td>\n",
       "      <td>1.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 23:59:00</th>\n",
       "      <td>64689.00</td>\n",
       "      <td>64700.00</td>\n",
       "      <td>64603.20</td>\n",
       "      <td>64603.20</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 00:00:00</th>\n",
       "      <td>64685.60</td>\n",
       "      <td>64742.90</td>\n",
       "      <td>64242.90</td>\n",
       "      <td>64438.40</td>\n",
       "      <td>1.644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2390401 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low     Close    Volume\n",
       "Open time (1M)                                                       \n",
       "2020-01-01 00:00:00   7169.71   7169.71   7165.44   7167.83  3509.860\n",
       "2020-01-01 00:01:00   7167.83   7168.28   7158.66   7159.95  3821.170\n",
       "2020-01-01 00:02:00   7161.03   7165.40   7161.03   7162.46  3041.710\n",
       "2020-01-01 00:03:00   7161.74   7164.27   7160.30   7161.03  3682.650\n",
       "2020-01-01 00:04:00   7161.03   7164.25   7160.15   7160.15  2936.690\n",
       "...                       ...       ...       ...       ...       ...\n",
       "2024-07-17 23:56:00  64637.90  64742.90  64242.90  64443.60     6.473\n",
       "2024-07-17 23:57:00  64443.60  64742.90  64242.90  64700.00     2.546\n",
       "2024-07-17 23:58:00  64700.00  64700.00  64603.20  64603.20     1.115\n",
       "2024-07-17 23:59:00  64689.00  64700.00  64603.20  64603.20     0.079\n",
       "2024-07-18 00:00:00  64685.60  64742.90  64242.90  64438.40     1.644\n",
       "\n",
       "[2390401 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_1m = df_temp_1m[: str(df_temp_4h.index[-1])]\n",
    "df_temp_1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (4h)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>7169.71</td>\n",
       "      <td>7207.23</td>\n",
       "      <td>7156.65</td>\n",
       "      <td>7202.48</td>\n",
       "      <td>3428.062092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 04:00:00</th>\n",
       "      <td>7202.48</td>\n",
       "      <td>9592.00</td>\n",
       "      <td>6871.45</td>\n",
       "      <td>7241.63</td>\n",
       "      <td>285722.475587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>7241.63</td>\n",
       "      <td>7243.46</td>\n",
       "      <td>7215.94</td>\n",
       "      <td>7223.72</td>\n",
       "      <td>3629.004242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 12:00:00</th>\n",
       "      <td>7223.71</td>\n",
       "      <td>7233.33</td>\n",
       "      <td>7178.00</td>\n",
       "      <td>7201.02</td>\n",
       "      <td>3491.032767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 16:00:00</th>\n",
       "      <td>7201.56</td>\n",
       "      <td>7236.58</td>\n",
       "      <td>7187.86</td>\n",
       "      <td>7220.85</td>\n",
       "      <td>3125.298729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 08:00:00</th>\n",
       "      <td>66196.50</td>\n",
       "      <td>66998.80</td>\n",
       "      <td>63555.00</td>\n",
       "      <td>65000.10</td>\n",
       "      <td>4.510771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 12:00:00</th>\n",
       "      <td>65000.10</td>\n",
       "      <td>66000.00</td>\n",
       "      <td>63555.00</td>\n",
       "      <td>65503.90</td>\n",
       "      <td>5.291817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 16:00:00</th>\n",
       "      <td>65446.30</td>\n",
       "      <td>66000.00</td>\n",
       "      <td>63892.40</td>\n",
       "      <td>64689.00</td>\n",
       "      <td>5.464083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 20:00:00</th>\n",
       "      <td>64669.70</td>\n",
       "      <td>64999.00</td>\n",
       "      <td>64240.00</td>\n",
       "      <td>64603.20</td>\n",
       "      <td>9.204992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 00:00:00</th>\n",
       "      <td>64685.60</td>\n",
       "      <td>64776.00</td>\n",
       "      <td>63700.00</td>\n",
       "      <td>64438.20</td>\n",
       "      <td>6.627105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9961 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low     Close         Volume\n",
       "Open time (4h)                                                            \n",
       "2020-01-01 00:00:00   7169.71   7207.23   7156.65   7202.48    3428.062092\n",
       "2020-01-01 04:00:00   7202.48   9592.00   6871.45   7241.63  285722.475587\n",
       "2020-01-01 08:00:00   7241.63   7243.46   7215.94   7223.72    3629.004242\n",
       "2020-01-01 12:00:00   7223.71   7233.33   7178.00   7201.02    3491.032767\n",
       "2020-01-01 16:00:00   7201.56   7236.58   7187.86   7220.85    3125.298729\n",
       "...                       ...       ...       ...       ...            ...\n",
       "2024-07-17 08:00:00  66196.50  66998.80  63555.00  65000.10       4.510771\n",
       "2024-07-17 12:00:00  65000.10  66000.00  63555.00  65503.90       5.291817\n",
       "2024-07-17 16:00:00  65446.30  66000.00  63892.40  64689.00       5.464083\n",
       "2024-07-17 20:00:00  64669.70  64999.00  64240.00  64603.20       9.204992\n",
       "2024-07-18 00:00:00  64685.60  64776.00  63700.00  64438.20       6.627105\n",
       "\n",
       "[9961 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OBV</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (4h)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>7169.71</td>\n",
       "      <td>7207.23</td>\n",
       "      <td>7156.65</td>\n",
       "      <td>7202.48</td>\n",
       "      <td>3428.062092</td>\n",
       "      <td>3428.062092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 04:00:00</th>\n",
       "      <td>7202.48</td>\n",
       "      <td>9592.00</td>\n",
       "      <td>6871.45</td>\n",
       "      <td>7241.63</td>\n",
       "      <td>285722.475587</td>\n",
       "      <td>289150.537679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>7241.63</td>\n",
       "      <td>7243.46</td>\n",
       "      <td>7215.94</td>\n",
       "      <td>7223.72</td>\n",
       "      <td>3629.004242</td>\n",
       "      <td>285521.533438</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 12:00:00</th>\n",
       "      <td>7223.71</td>\n",
       "      <td>7233.33</td>\n",
       "      <td>7178.00</td>\n",
       "      <td>7201.02</td>\n",
       "      <td>3491.032767</td>\n",
       "      <td>282030.500671</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 16:00:00</th>\n",
       "      <td>7201.56</td>\n",
       "      <td>7236.58</td>\n",
       "      <td>7187.86</td>\n",
       "      <td>7220.85</td>\n",
       "      <td>3125.298729</td>\n",
       "      <td>285155.799400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 08:00:00</th>\n",
       "      <td>66196.50</td>\n",
       "      <td>66998.80</td>\n",
       "      <td>63555.00</td>\n",
       "      <td>65000.10</td>\n",
       "      <td>4.510771</td>\n",
       "      <td>793937.920835</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 12:00:00</th>\n",
       "      <td>65000.10</td>\n",
       "      <td>66000.00</td>\n",
       "      <td>63555.00</td>\n",
       "      <td>65503.90</td>\n",
       "      <td>5.291817</td>\n",
       "      <td>793943.212652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 16:00:00</th>\n",
       "      <td>65446.30</td>\n",
       "      <td>66000.00</td>\n",
       "      <td>63892.40</td>\n",
       "      <td>64689.00</td>\n",
       "      <td>5.464083</td>\n",
       "      <td>793937.748569</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 20:00:00</th>\n",
       "      <td>64669.70</td>\n",
       "      <td>64999.00</td>\n",
       "      <td>64240.00</td>\n",
       "      <td>64603.20</td>\n",
       "      <td>9.204992</td>\n",
       "      <td>793928.543577</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-18 00:00:00</th>\n",
       "      <td>64685.60</td>\n",
       "      <td>64776.00</td>\n",
       "      <td>63700.00</td>\n",
       "      <td>64438.20</td>\n",
       "      <td>6.627105</td>\n",
       "      <td>793921.916472</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9961 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low     Close         Volume  \\\n",
       "Open time (4h)                                                               \n",
       "2020-01-01 00:00:00   7169.71   7207.23   7156.65   7202.48    3428.062092   \n",
       "2020-01-01 04:00:00   7202.48   9592.00   6871.45   7241.63  285722.475587   \n",
       "2020-01-01 08:00:00   7241.63   7243.46   7215.94   7223.72    3629.004242   \n",
       "2020-01-01 12:00:00   7223.71   7233.33   7178.00   7201.02    3491.032767   \n",
       "2020-01-01 16:00:00   7201.56   7236.58   7187.86   7220.85    3125.298729   \n",
       "...                       ...       ...       ...       ...            ...   \n",
       "2024-07-17 08:00:00  66196.50  66998.80  63555.00  65000.10       4.510771   \n",
       "2024-07-17 12:00:00  65000.10  66000.00  63555.00  65503.90       5.291817   \n",
       "2024-07-17 16:00:00  65446.30  66000.00  63892.40  64689.00       5.464083   \n",
       "2024-07-17 20:00:00  64669.70  64999.00  64240.00  64603.20       9.204992   \n",
       "2024-07-18 00:00:00  64685.60  64776.00  63700.00  64438.20       6.627105   \n",
       "\n",
       "                               OBV  Signal  \n",
       "Open time (4h)                              \n",
       "2020-01-01 00:00:00    3428.062092       0  \n",
       "2020-01-01 04:00:00  289150.537679       1  \n",
       "2020-01-01 08:00:00  285521.533438      -1  \n",
       "2020-01-01 12:00:00  282030.500671      -1  \n",
       "2020-01-01 16:00:00  285155.799400       1  \n",
       "...                            ...     ...  \n",
       "2024-07-17 08:00:00  793937.920835      -1  \n",
       "2024-07-17 12:00:00  793943.212652       1  \n",
       "2024-07-17 16:00:00  793937.748569      -1  \n",
       "2024-07-17 20:00:00  793928.543577      -1  \n",
       "2024-07-18 00:00:00  793921.916472      -1  \n",
       "\n",
       "[9961 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate The On-Balance Volume (OBV)\n",
    "temp_signal_df = calculate_obv(copy.deepcopy(df_temp_4h), fillna = True)\n",
    "\n",
    "# Generate Signals Using OBV\n",
    "temp_signal_df = generate_obv_signals(temp_signal_df)\n",
    "temp_signal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>entry price</th>\n",
       "      <th>close price</th>\n",
       "      <th>action</th>\n",
       "      <th>PNL</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (4h)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 04:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7202.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.331664e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 05:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7202.48</td>\n",
       "      <td>9592.00</td>\n",
       "      <td>tp</td>\n",
       "      <td>33.176350</td>\n",
       "      <td>1.331664e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7241.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.338899e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 16:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7241.63</td>\n",
       "      <td>7201.56</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.553328</td>\n",
       "      <td>1.338899e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 16:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7201.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.346322e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 08:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>64670.80</td>\n",
       "      <td>66196.50</td>\n",
       "      <td>direction</td>\n",
       "      <td>2.359179</td>\n",
       "      <td>9.927818e+47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 08:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>66196.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.010626e+48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 12:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>66196.50</td>\n",
       "      <td>65000.10</td>\n",
       "      <td>direction</td>\n",
       "      <td>1.807346</td>\n",
       "      <td>1.010626e+48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 12:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>65000.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017462e+48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-17 16:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>65000.10</td>\n",
       "      <td>65446.30</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.686460</td>\n",
       "      <td>1.017462e+48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12716 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    direction  entry price  close price     action        PNL  \\\n",
       "Open time (4h)                                                                  \n",
       "2020-01-01 04:00:00      long      7202.48         0.00       None        NaN   \n",
       "2020-01-01 05:00:00     short      7202.48      9592.00         tp  33.176350   \n",
       "2020-01-01 08:00:00     short      7241.63         0.00       None        NaN   \n",
       "2020-01-01 16:00:00      long      7241.63      7201.56  direction   0.553328   \n",
       "2020-01-01 16:00:00      long      7201.56         0.00       None        NaN   \n",
       "...                       ...          ...          ...        ...        ...   \n",
       "2024-07-17 08:00:00     short     64670.80     66196.50  direction   2.359179   \n",
       "2024-07-17 08:00:00     short     66196.50         0.00       None        NaN   \n",
       "2024-07-17 12:00:00      long     66196.50     65000.10  direction   1.807346   \n",
       "2024-07-17 12:00:00      long     65000.10         0.00       None        NaN   \n",
       "2024-07-17 16:00:00     short     65000.10     65446.30  direction   0.686460   \n",
       "\n",
       "                          Balance  \n",
       "Open time (4h)                     \n",
       "2020-01-01 04:00:00  1.331664e+03  \n",
       "2020-01-01 05:00:00  1.331664e+03  \n",
       "2020-01-01 08:00:00  1.338899e+03  \n",
       "2020-01-01 16:00:00  1.338899e+03  \n",
       "2020-01-01 16:00:00  1.346322e+03  \n",
       "...                           ...  \n",
       "2024-07-17 08:00:00  9.927818e+47  \n",
       "2024-07-17 08:00:00  1.010626e+48  \n",
       "2024-07-17 12:00:00  1.010626e+48  \n",
       "2024-07-17 12:00:00  1.017462e+48  \n",
       "2024-07-17 16:00:00  1.017462e+48  \n",
       "\n",
       "[12716 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_backtest_df = generate_backtest_df(copy.deepcopy(temp_signal_df), df_temp_1m, temp_signal_df[:20].copy())\n",
    "temp_backtest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll stats calculated!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Generate the stats df\n",
    "new_ledger_with_all_pnl = calculate_pnl_sum_all(temp_backtest_df.reset_index())\n",
    "_, stats_df = calculate_all_statistics(new_ledger_with_all_pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28312.47"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df['Total PnL (%)'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OBV</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (4h)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>7169.71</td>\n",
       "      <td>7207.23</td>\n",
       "      <td>7156.65</td>\n",
       "      <td>7202.48</td>\n",
       "      <td>3428.062092</td>\n",
       "      <td>3428.062092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 04:00:00</th>\n",
       "      <td>7202.48</td>\n",
       "      <td>9592.00</td>\n",
       "      <td>6871.45</td>\n",
       "      <td>7241.63</td>\n",
       "      <td>285722.475587</td>\n",
       "      <td>289150.537679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>7241.63</td>\n",
       "      <td>7243.46</td>\n",
       "      <td>7215.94</td>\n",
       "      <td>7223.72</td>\n",
       "      <td>3629.004242</td>\n",
       "      <td>285521.533438</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 12:00:00</th>\n",
       "      <td>7223.71</td>\n",
       "      <td>7233.33</td>\n",
       "      <td>7178.00</td>\n",
       "      <td>7201.02</td>\n",
       "      <td>3491.032767</td>\n",
       "      <td>282030.500671</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 16:00:00</th>\n",
       "      <td>7201.56</td>\n",
       "      <td>7236.58</td>\n",
       "      <td>7187.86</td>\n",
       "      <td>7220.85</td>\n",
       "      <td>3125.298729</td>\n",
       "      <td>285155.799400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 20:00:00</th>\n",
       "      <td>7220.41</td>\n",
       "      <td>7253.21</td>\n",
       "      <td>7216.21</td>\n",
       "      <td>7242.21</td>\n",
       "      <td>3440.883271</td>\n",
       "      <td>288596.682671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 00:00:00</th>\n",
       "      <td>7242.21</td>\n",
       "      <td>7243.41</td>\n",
       "      <td>7187.84</td>\n",
       "      <td>7197.77</td>\n",
       "      <td>3633.728296</td>\n",
       "      <td>284962.954375</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 04:00:00</th>\n",
       "      <td>7197.77</td>\n",
       "      <td>7212.59</td>\n",
       "      <td>7155.02</td>\n",
       "      <td>7169.51</td>\n",
       "      <td>3370.041933</td>\n",
       "      <td>281592.912442</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 08:00:00</th>\n",
       "      <td>7169.51</td>\n",
       "      <td>7169.51</td>\n",
       "      <td>7116.48</td>\n",
       "      <td>7134.87</td>\n",
       "      <td>3485.338125</td>\n",
       "      <td>278107.574317</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 12:00:00</th>\n",
       "      <td>7135.52</td>\n",
       "      <td>7181.53</td>\n",
       "      <td>7105.17</td>\n",
       "      <td>7160.60</td>\n",
       "      <td>3261.590162</td>\n",
       "      <td>281369.164479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 16:00:00</th>\n",
       "      <td>7160.61</td>\n",
       "      <td>7169.15</td>\n",
       "      <td>7106.01</td>\n",
       "      <td>7133.94</td>\n",
       "      <td>3255.112733</td>\n",
       "      <td>278114.051746</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 20:00:00</th>\n",
       "      <td>7133.95</td>\n",
       "      <td>7151.00</td>\n",
       "      <td>6934.53</td>\n",
       "      <td>6975.70</td>\n",
       "      <td>3085.910929</td>\n",
       "      <td>275028.140817</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 00:00:00</th>\n",
       "      <td>6975.70</td>\n",
       "      <td>6995.47</td>\n",
       "      <td>6942.54</td>\n",
       "      <td>6973.69</td>\n",
       "      <td>3391.022896</td>\n",
       "      <td>271637.117921</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 04:00:00</th>\n",
       "      <td>6974.16</td>\n",
       "      <td>6975.69</td>\n",
       "      <td>6871.45</td>\n",
       "      <td>6956.86</td>\n",
       "      <td>3046.781025</td>\n",
       "      <td>268590.336896</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00</th>\n",
       "      <td>6957.16</td>\n",
       "      <td>7258.41</td>\n",
       "      <td>6940.07</td>\n",
       "      <td>7201.75</td>\n",
       "      <td>4497.399350</td>\n",
       "      <td>273087.736246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 12:00:00</th>\n",
       "      <td>7201.75</td>\n",
       "      <td>7600.00</td>\n",
       "      <td>7187.84</td>\n",
       "      <td>7312.87</td>\n",
       "      <td>4344.825125</td>\n",
       "      <td>277432.561371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 16:00:00</th>\n",
       "      <td>7312.31</td>\n",
       "      <td>7375.28</td>\n",
       "      <td>7234.72</td>\n",
       "      <td>7254.05</td>\n",
       "      <td>3065.431738</td>\n",
       "      <td>274367.129633</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 20:00:00</th>\n",
       "      <td>7254.05</td>\n",
       "      <td>7399.99</td>\n",
       "      <td>7253.31</td>\n",
       "      <td>7342.00</td>\n",
       "      <td>3162.416233</td>\n",
       "      <td>277529.545867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:00:00</th>\n",
       "      <td>7342.00</td>\n",
       "      <td>7361.39</td>\n",
       "      <td>7260.51</td>\n",
       "      <td>7302.13</td>\n",
       "      <td>2998.414583</td>\n",
       "      <td>274531.131283</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 04:00:00</th>\n",
       "      <td>7302.13</td>\n",
       "      <td>7349.19</td>\n",
       "      <td>7281.09</td>\n",
       "      <td>7327.91</td>\n",
       "      <td>3075.942092</td>\n",
       "      <td>277607.073375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 08:00:00</th>\n",
       "      <td>7327.92</td>\n",
       "      <td>7365.29</td>\n",
       "      <td>7311.60</td>\n",
       "      <td>7354.17</td>\n",
       "      <td>3222.759379</td>\n",
       "      <td>280829.832754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 12:00:00</th>\n",
       "      <td>7354.17</td>\n",
       "      <td>7369.35</td>\n",
       "      <td>7310.40</td>\n",
       "      <td>7318.17</td>\n",
       "      <td>3226.013892</td>\n",
       "      <td>277603.818863</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 16:00:00</th>\n",
       "      <td>7314.78</td>\n",
       "      <td>7339.15</td>\n",
       "      <td>7290.72</td>\n",
       "      <td>7316.97</td>\n",
       "      <td>3089.091829</td>\n",
       "      <td>274514.727033</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 20:00:00</th>\n",
       "      <td>7317.70</td>\n",
       "      <td>7400.00</td>\n",
       "      <td>7260.00</td>\n",
       "      <td>7305.62</td>\n",
       "      <td>3019.246050</td>\n",
       "      <td>271495.480983</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05 00:00:00</th>\n",
       "      <td>7305.68</td>\n",
       "      <td>7367.47</td>\n",
       "      <td>7282.39</td>\n",
       "      <td>7348.99</td>\n",
       "      <td>2917.209042</td>\n",
       "      <td>274412.690025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close         Volume  \\\n",
       "Open time (4h)                                                           \n",
       "2020-01-01 00:00:00  7169.71  7207.23  7156.65  7202.48    3428.062092   \n",
       "2020-01-01 04:00:00  7202.48  9592.00  6871.45  7241.63  285722.475587   \n",
       "2020-01-01 08:00:00  7241.63  7243.46  7215.94  7223.72    3629.004242   \n",
       "2020-01-01 12:00:00  7223.71  7233.33  7178.00  7201.02    3491.032767   \n",
       "2020-01-01 16:00:00  7201.56  7236.58  7187.86  7220.85    3125.298729   \n",
       "2020-01-01 20:00:00  7220.41  7253.21  7216.21  7242.21    3440.883271   \n",
       "2020-01-02 00:00:00  7242.21  7243.41  7187.84  7197.77    3633.728296   \n",
       "2020-01-02 04:00:00  7197.77  7212.59  7155.02  7169.51    3370.041933   \n",
       "2020-01-02 08:00:00  7169.51  7169.51  7116.48  7134.87    3485.338125   \n",
       "2020-01-02 12:00:00  7135.52  7181.53  7105.17  7160.60    3261.590162   \n",
       "2020-01-02 16:00:00  7160.61  7169.15  7106.01  7133.94    3255.112733   \n",
       "2020-01-02 20:00:00  7133.95  7151.00  6934.53  6975.70    3085.910929   \n",
       "2020-01-03 00:00:00  6975.70  6995.47  6942.54  6973.69    3391.022896   \n",
       "2020-01-03 04:00:00  6974.16  6975.69  6871.45  6956.86    3046.781025   \n",
       "2020-01-03 08:00:00  6957.16  7258.41  6940.07  7201.75    4497.399350   \n",
       "2020-01-03 12:00:00  7201.75  7600.00  7187.84  7312.87    4344.825125   \n",
       "2020-01-03 16:00:00  7312.31  7375.28  7234.72  7254.05    3065.431738   \n",
       "2020-01-03 20:00:00  7254.05  7399.99  7253.31  7342.00    3162.416233   \n",
       "2020-01-04 00:00:00  7342.00  7361.39  7260.51  7302.13    2998.414583   \n",
       "2020-01-04 04:00:00  7302.13  7349.19  7281.09  7327.91    3075.942092   \n",
       "2020-01-04 08:00:00  7327.92  7365.29  7311.60  7354.17    3222.759379   \n",
       "2020-01-04 12:00:00  7354.17  7369.35  7310.40  7318.17    3226.013892   \n",
       "2020-01-04 16:00:00  7314.78  7339.15  7290.72  7316.97    3089.091829   \n",
       "2020-01-04 20:00:00  7317.70  7400.00  7260.00  7305.62    3019.246050   \n",
       "2020-01-05 00:00:00  7305.68  7367.47  7282.39  7348.99    2917.209042   \n",
       "\n",
       "                               OBV  Signal  \n",
       "Open time (4h)                              \n",
       "2020-01-01 00:00:00    3428.062092       0  \n",
       "2020-01-01 04:00:00  289150.537679       1  \n",
       "2020-01-01 08:00:00  285521.533438      -1  \n",
       "2020-01-01 12:00:00  282030.500671      -1  \n",
       "2020-01-01 16:00:00  285155.799400       1  \n",
       "2020-01-01 20:00:00  288596.682671       1  \n",
       "2020-01-02 00:00:00  284962.954375      -1  \n",
       "2020-01-02 04:00:00  281592.912442      -1  \n",
       "2020-01-02 08:00:00  278107.574317      -1  \n",
       "2020-01-02 12:00:00  281369.164479       1  \n",
       "2020-01-02 16:00:00  278114.051746      -1  \n",
       "2020-01-02 20:00:00  275028.140817      -1  \n",
       "2020-01-03 00:00:00  271637.117921      -1  \n",
       "2020-01-03 04:00:00  268590.336896      -1  \n",
       "2020-01-03 08:00:00  273087.736246       1  \n",
       "2020-01-03 12:00:00  277432.561371       1  \n",
       "2020-01-03 16:00:00  274367.129633      -1  \n",
       "2020-01-03 20:00:00  277529.545867       1  \n",
       "2020-01-04 00:00:00  274531.131283      -1  \n",
       "2020-01-04 04:00:00  277607.073375       1  \n",
       "2020-01-04 08:00:00  280829.832754       1  \n",
       "2020-01-04 12:00:00  277603.818863      -1  \n",
       "2020-01-04 16:00:00  274514.727033      -1  \n",
       "2020-01-04 20:00:00  271495.480983      -1  \n",
       "2020-01-05 00:00:00  274412.690025       0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_signal_df_last = temp_signal_df[:25].copy()\n",
    "temp_signal_df_last.loc[temp_signal_df_last.index[-1], 'Signal'] = 0\n",
    "temp_signal_df_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (1M)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>7169.71</td>\n",
       "      <td>7169.71</td>\n",
       "      <td>7165.44</td>\n",
       "      <td>7167.83</td>\n",
       "      <td>3509.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:00</th>\n",
       "      <td>7167.83</td>\n",
       "      <td>7168.28</td>\n",
       "      <td>7158.66</td>\n",
       "      <td>7159.95</td>\n",
       "      <td>3821.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:02:00</th>\n",
       "      <td>7161.03</td>\n",
       "      <td>7165.40</td>\n",
       "      <td>7161.03</td>\n",
       "      <td>7162.46</td>\n",
       "      <td>3041.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:03:00</th>\n",
       "      <td>7161.74</td>\n",
       "      <td>7164.27</td>\n",
       "      <td>7160.30</td>\n",
       "      <td>7161.03</td>\n",
       "      <td>3682.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:04:00</th>\n",
       "      <td>7161.03</td>\n",
       "      <td>7164.25</td>\n",
       "      <td>7160.15</td>\n",
       "      <td>7160.15</td>\n",
       "      <td>2936.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 23:56:00</th>\n",
       "      <td>7313.30</td>\n",
       "      <td>7314.82</td>\n",
       "      <td>7304.47</td>\n",
       "      <td>7304.59</td>\n",
       "      <td>2932.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 23:57:00</th>\n",
       "      <td>7304.59</td>\n",
       "      <td>7306.77</td>\n",
       "      <td>7299.27</td>\n",
       "      <td>7300.23</td>\n",
       "      <td>2656.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 23:58:00</th>\n",
       "      <td>7300.23</td>\n",
       "      <td>7303.15</td>\n",
       "      <td>7296.64</td>\n",
       "      <td>7297.37</td>\n",
       "      <td>2991.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 23:59:00</th>\n",
       "      <td>7297.37</td>\n",
       "      <td>7305.82</td>\n",
       "      <td>7294.77</td>\n",
       "      <td>7305.62</td>\n",
       "      <td>2505.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05 00:00:00</th>\n",
       "      <td>7305.68</td>\n",
       "      <td>7305.69</td>\n",
       "      <td>7296.57</td>\n",
       "      <td>7301.90</td>\n",
       "      <td>3341.419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5761 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close    Volume\n",
       "Open time (1M)                                                   \n",
       "2020-01-01 00:00:00  7169.71  7169.71  7165.44  7167.83  3509.860\n",
       "2020-01-01 00:01:00  7167.83  7168.28  7158.66  7159.95  3821.170\n",
       "2020-01-01 00:02:00  7161.03  7165.40  7161.03  7162.46  3041.710\n",
       "2020-01-01 00:03:00  7161.74  7164.27  7160.30  7161.03  3682.650\n",
       "2020-01-01 00:04:00  7161.03  7164.25  7160.15  7160.15  2936.690\n",
       "...                      ...      ...      ...      ...       ...\n",
       "2020-01-04 23:56:00  7313.30  7314.82  7304.47  7304.59  2932.650\n",
       "2020-01-04 23:57:00  7304.59  7306.77  7299.27  7300.23  2656.891\n",
       "2020-01-04 23:58:00  7300.23  7303.15  7296.64  7297.37  2991.368\n",
       "2020-01-04 23:59:00  7297.37  7305.82  7294.77  7305.62  2505.819\n",
       "2020-01-05 00:00:00  7305.68  7305.69  7296.57  7301.90  3341.419\n",
       "\n",
       "[5761 rows x 5 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_1m_last = df_temp_1m[str(temp_signal_df_last.index[0]): str(temp_signal_df_last.index[-1])].copy()\n",
    "df_temp_1m_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>entry price</th>\n",
       "      <th>close price</th>\n",
       "      <th>action</th>\n",
       "      <th>PNL</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open time (4h)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 04:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7202.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1331.663504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 05:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7202.48</td>\n",
       "      <td>9592.00</td>\n",
       "      <td>tp</td>\n",
       "      <td>33.176350</td>\n",
       "      <td>1331.663504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7241.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1338.898811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 16:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7241.63</td>\n",
       "      <td>7201.56</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.553328</td>\n",
       "      <td>1338.898811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 16:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7201.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1346.322483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 00:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7201.56</td>\n",
       "      <td>7242.21</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.564461</td>\n",
       "      <td>1346.322483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 00:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7242.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366.021457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 12:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7242.21</td>\n",
       "      <td>7135.52</td>\n",
       "      <td>direction</td>\n",
       "      <td>1.473169</td>\n",
       "      <td>1366.021457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 12:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7135.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1370.688076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 16:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7135.52</td>\n",
       "      <td>7160.61</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.351621</td>\n",
       "      <td>1370.688076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 16:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7160.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1409.495523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7160.61</td>\n",
       "      <td>6957.16</td>\n",
       "      <td>direction</td>\n",
       "      <td>2.841238</td>\n",
       "      <td>1409.495523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>6957.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1481.292501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 14:11:00</th>\n",
       "      <td>long</td>\n",
       "      <td>6957.16</td>\n",
       "      <td>7312.24</td>\n",
       "      <td>tp</td>\n",
       "      <td>5.103807</td>\n",
       "      <td>1481.292501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 16:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7312.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1492.946401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 20:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7312.31</td>\n",
       "      <td>7254.05</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.796739</td>\n",
       "      <td>1492.946401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 20:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7254.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1510.897979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7254.05</td>\n",
       "      <td>7342.00</td>\n",
       "      <td>direction</td>\n",
       "      <td>1.212426</td>\n",
       "      <td>1510.897979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7342.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1518.951671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 04:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7342.00</td>\n",
       "      <td>7302.13</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.543040</td>\n",
       "      <td>1518.951671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 04:00:00</th>\n",
       "      <td>long</td>\n",
       "      <td>7302.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1529.624870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 12:00:00</th>\n",
       "      <td>short</td>\n",
       "      <td>7302.13</td>\n",
       "      <td>7354.17</td>\n",
       "      <td>direction</td>\n",
       "      <td>0.712669</td>\n",
       "      <td>1529.624870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    direction  entry price  close price     action        PNL  \\\n",
       "Open time (4h)                                                                  \n",
       "2020-01-01 04:00:00      long      7202.48         0.00       None        NaN   \n",
       "2020-01-01 05:00:00     short      7202.48      9592.00         tp  33.176350   \n",
       "2020-01-01 08:00:00     short      7241.63         0.00       None        NaN   \n",
       "2020-01-01 16:00:00      long      7241.63      7201.56  direction   0.553328   \n",
       "2020-01-01 16:00:00      long      7201.56         0.00       None        NaN   \n",
       "2020-01-02 00:00:00     short      7201.56      7242.21  direction   0.564461   \n",
       "2020-01-02 00:00:00     short      7242.21         0.00       None        NaN   \n",
       "2020-01-02 12:00:00      long      7242.21      7135.52  direction   1.473169   \n",
       "2020-01-02 12:00:00      long      7135.52         0.00       None        NaN   \n",
       "2020-01-02 16:00:00     short      7135.52      7160.61  direction   0.351621   \n",
       "2020-01-02 16:00:00     short      7160.61         0.00       None        NaN   \n",
       "2020-01-03 08:00:00      long      7160.61      6957.16  direction   2.841238   \n",
       "2020-01-03 08:00:00      long      6957.16         0.00       None        NaN   \n",
       "2020-01-03 14:11:00      long      6957.16      7312.24         tp   5.103807   \n",
       "2020-01-03 16:00:00     short      7312.31         0.00       None        NaN   \n",
       "2020-01-03 20:00:00      long      7312.31      7254.05  direction   0.796739   \n",
       "2020-01-03 20:00:00      long      7254.05         0.00       None        NaN   \n",
       "2020-01-04 00:00:00     short      7254.05      7342.00  direction   1.212426   \n",
       "2020-01-04 00:00:00     short      7342.00         0.00       None        NaN   \n",
       "2020-01-04 04:00:00      long      7342.00      7302.13  direction   0.543040   \n",
       "2020-01-04 04:00:00      long      7302.13         0.00       None        NaN   \n",
       "2020-01-04 12:00:00     short      7302.13      7354.17  direction   0.712669   \n",
       "\n",
       "                         Balance  \n",
       "Open time (4h)                    \n",
       "2020-01-01 04:00:00  1331.663504  \n",
       "2020-01-01 05:00:00  1331.663504  \n",
       "2020-01-01 08:00:00  1338.898811  \n",
       "2020-01-01 16:00:00  1338.898811  \n",
       "2020-01-01 16:00:00  1346.322483  \n",
       "2020-01-02 00:00:00  1346.322483  \n",
       "2020-01-02 00:00:00  1366.021457  \n",
       "2020-01-02 12:00:00  1366.021457  \n",
       "2020-01-02 12:00:00  1370.688076  \n",
       "2020-01-02 16:00:00  1370.688076  \n",
       "2020-01-02 16:00:00  1409.495523  \n",
       "2020-01-03 08:00:00  1409.495523  \n",
       "2020-01-03 08:00:00  1481.292501  \n",
       "2020-01-03 14:11:00  1481.292501  \n",
       "2020-01-03 16:00:00  1492.946401  \n",
       "2020-01-03 20:00:00  1492.946401  \n",
       "2020-01-03 20:00:00  1510.897979  \n",
       "2020-01-04 00:00:00  1510.897979  \n",
       "2020-01-04 00:00:00  1518.951671  \n",
       "2020-01-04 04:00:00  1518.951671  \n",
       "2020-01-04 04:00:00  1529.624870  \n",
       "2020-01-04 12:00:00  1529.624870  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_backtest_df_last = generate_backtest_df(copy.deepcopy(temp_signal_df_last), df_temp_1m_last)\n",
    "temp_backtest_df_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Code's Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "1min 57s  0 ns per loop (mean  std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "df_with_all_pnl = calculate_pnl_sum_all(copy.deepcopy(temp_backtest_df))\n",
    "stats_dict, stats_df = calculate_all_statistics(df_with_all_pnl)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Code's Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "1.36 s  21.3 ms per loop (mean  std. dev. of 5 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 3\n",
    "df_with_all_pnl = calculate_pnl_sum_all(copy.deepcopy(temp_backtest_df))\n",
    "stats_dict, stats_df = calculate_all_statistics(df_with_all_pnl)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, more changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "233 ms  8.92 ms per loop (mean  std. dev. of 5 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 3\n",
    "df_with_all_pnl = calculate_pnl_sum_all(copy.deepcopy(temp_backtest_df))\n",
    "stats_dict, stats_df = calculate_all_statistics(df_with_all_pnl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***More Later!***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
